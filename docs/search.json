[
  {
    "objectID": "projects.html#predicting-children-hotel-stay-booking-using-tidymodels",
    "href": "projects.html#predicting-children-hotel-stay-booking-using-tidymodels",
    "title": "RJ Dela Peña",
    "section": "Predicting Children Hotel Stay Booking using TidyModels",
    "text": "Predicting Children Hotel Stay Booking using TidyModels"
  },
  {
    "objectID": "projects.html#global-livestock-trend-analysis",
    "href": "projects.html#global-livestock-trend-analysis",
    "title": "RJ Dela Peña",
    "section": "Global Livestock Trend Analysis",
    "text": "Global Livestock Trend Analysis"
  },
  {
    "objectID": "projects.html#sales-and-quantity-forecasting-using-tidymodels-modeltime-and-timetk",
    "href": "projects.html#sales-and-quantity-forecasting-using-tidymodels-modeltime-and-timetk",
    "title": "RJ Dela Peña",
    "section": "Sales and Quantity Forecasting using TidyModels, modeltime and timetk",
    "text": "Sales and Quantity Forecasting using TidyModels, modeltime and timetk"
  },
  {
    "objectID": "projects/store_sales_modelling/sales_analysis.html",
    "href": "projects/store_sales_modelling/sales_analysis.html",
    "title": "Stores Sales",
    "section": "",
    "text": "Store Sales Forecasting Data contains customer transaction records. Our goal is to create a forecast model that will help us identify the future movement of our Sales and Quantity for inventory management. Developing this type of model can help us better assess our quarterly or yearly sales performance and have a more accurate product re-stocking based on order quantity projection.\n\n#Import Libraries\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(forecast)\nlibrary(tidymodels)\nlibrary(modeltime)\nlibrary(timetk)\n\n#Import Data\nraw_sales_data = read_csv(\"stores_sales_forecasting.csv\") %&gt;% as_tibble()\n\n\n#Check row id if unique\nnrow(raw_sales_data) == raw_sales_data$`Row ID` %&gt;% unique() %&gt;% length()\n\n[1] TRUE\n\n#Row Ids are unique.\n\n\n#Check each variable, Uni and Bivariate analysis\n\n#We have a date column, lets convert it into date object so we can use it on time series plots\n\n\nraw_sales_data = raw_sales_data %&gt;% \n  mutate(\n    `Order Date` = as.Date(`Order Date`,\"%m/%d/%Y\"),\n    `Ship Date` = as.Date(`Ship Date`,\"%m/%d/%Y\")\n  )\n\n\n\n#Check frequency of Ship Mode\nraw_sales_data %&gt;% \n  ggplot(aes(x = `Ship Mode`)) +\n  geom_bar()\n\n\n\n#Standard Class is the most common way of shipping products\n\n#Which segment is the most common? and what are other segment categories??\n\nraw_sales_data %&gt;% \n  ggplot(aes(x = Segment)) +\n  geom_bar()\n\n\n\n#Majority of our segment came from consumer.\n\nraw_sales_data %&gt;% \n  ggplot(aes(x = reorder(State,State,function(x) + length(x) ))) +\n  geom_bar() +\n  coord_flip() +\n  labs(\n    x = \"State\"\n  )\n\n\n\n#So our top five for states sales are \n#California, New Yori, Texas, Pennsylvania and Illinois\n\n#Table for better view\nraw_sales_data %&gt;% \n  count(State, sort = TRUE)\n\n# A tibble: 48 × 2\n   State            n\n   &lt;chr&gt;        &lt;int&gt;\n 1 California     444\n 2 New York       236\n 3 Texas          202\n 4 Pennsylvania   125\n 5 Illinois       123\n 6 Washington     114\n 7 Ohio            93\n 8 Florida         85\n 9 Virginia        52\n10 Colorado        51\n# ℹ 38 more rows\n\n#Check Region\nraw_sales_data %&gt;% \n  ggplot(aes(x = reorder(Region,Region, function(x) + length(x)) )) +\n  geom_bar() +\n  labs(\n    x = \"Region\"\n  )\n\n\n\n#We have most of our sales coming from West Region\n\n#Lets check Product Sub Category\n\nraw_sales_data %&gt;% \n  ggplot(aes(x = reorder(`Sub-Category`,`Sub-Category`,function(x) - length(x)))) +\n  geom_bar() +\n  labs(\n    x = \"Sub-Category\"\n  )\n\n\n\n#Majority of our sales came from Furnishing\n\n#Check range of quantity and distribution\nrange(raw_sales_data$Quantity)\n\n[1]  1 14\n\n#Ranges from 1 to 14\n\n#Check shape\nraw_sales_data %&gt;% \n  ggplot(aes(x = Quantity)) +\n  geom_histogram()\n\n\n\n#Positively Skewed. 3 seems to be the most common quantity for orders\n\n\n#Check discounts?\nrange(raw_sales_data$Discount)\n\n[1] 0.0 0.7\n\n#highest Discount we gave was 70% off\n\nraw_sales_data %&gt;% \n  ggplot(aes(x = Discount)) +\n  geom_histogram()\n\n\n\n#As expected, highest count was zero for discount, since not all the time we are giving off discount\n\n\n#Check profit\nsummary(raw_sales_data$Profit)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-1862.312   -12.849     7.775     8.699    33.727  1013.127 \n\n#For profit -- we have negative profit, average is 8 USD while max is at 1013.127 USD"
  },
  {
    "objectID": "projects/store_sales_modelling/sales_analysis.html#overview",
    "href": "projects/store_sales_modelling/sales_analysis.html#overview",
    "title": "Stores Sales",
    "section": "",
    "text": "Store Sales Forecasting Data contains customer transaction records. Our goal is to create a forecast model that will help us identify the future movement of our Sales and Quantity for inventory management. Developing this type of model can help us better assess our quarterly or yearly sales performance and have a more accurate product re-stocking based on order quantity projection.\n\n#Import Libraries\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(forecast)\nlibrary(tidymodels)\nlibrary(modeltime)\nlibrary(timetk)\n\n#Import Data\nraw_sales_data = read_csv(\"stores_sales_forecasting.csv\") %&gt;% as_tibble()\n\n\n#Check row id if unique\nnrow(raw_sales_data) == raw_sales_data$`Row ID` %&gt;% unique() %&gt;% length()\n\n[1] TRUE\n\n#Row Ids are unique.\n\n\n#Check each variable, Uni and Bivariate analysis\n\n#We have a date column, lets convert it into date object so we can use it on time series plots\n\n\nraw_sales_data = raw_sales_data %&gt;% \n  mutate(\n    `Order Date` = as.Date(`Order Date`,\"%m/%d/%Y\"),\n    `Ship Date` = as.Date(`Ship Date`,\"%m/%d/%Y\")\n  )\n\n\n\n#Check frequency of Ship Mode\nraw_sales_data %&gt;% \n  ggplot(aes(x = `Ship Mode`)) +\n  geom_bar()\n\n\n\n#Standard Class is the most common way of shipping products\n\n#Which segment is the most common? and what are other segment categories??\n\nraw_sales_data %&gt;% \n  ggplot(aes(x = Segment)) +\n  geom_bar()\n\n\n\n#Majority of our segment came from consumer.\n\nraw_sales_data %&gt;% \n  ggplot(aes(x = reorder(State,State,function(x) + length(x) ))) +\n  geom_bar() +\n  coord_flip() +\n  labs(\n    x = \"State\"\n  )\n\n\n\n#So our top five for states sales are \n#California, New Yori, Texas, Pennsylvania and Illinois\n\n#Table for better view\nraw_sales_data %&gt;% \n  count(State, sort = TRUE)\n\n# A tibble: 48 × 2\n   State            n\n   &lt;chr&gt;        &lt;int&gt;\n 1 California     444\n 2 New York       236\n 3 Texas          202\n 4 Pennsylvania   125\n 5 Illinois       123\n 6 Washington     114\n 7 Ohio            93\n 8 Florida         85\n 9 Virginia        52\n10 Colorado        51\n# ℹ 38 more rows\n\n#Check Region\nraw_sales_data %&gt;% \n  ggplot(aes(x = reorder(Region,Region, function(x) + length(x)) )) +\n  geom_bar() +\n  labs(\n    x = \"Region\"\n  )\n\n\n\n#We have most of our sales coming from West Region\n\n#Lets check Product Sub Category\n\nraw_sales_data %&gt;% \n  ggplot(aes(x = reorder(`Sub-Category`,`Sub-Category`,function(x) - length(x)))) +\n  geom_bar() +\n  labs(\n    x = \"Sub-Category\"\n  )\n\n\n\n#Majority of our sales came from Furnishing\n\n#Check range of quantity and distribution\nrange(raw_sales_data$Quantity)\n\n[1]  1 14\n\n#Ranges from 1 to 14\n\n#Check shape\nraw_sales_data %&gt;% \n  ggplot(aes(x = Quantity)) +\n  geom_histogram()\n\n\n\n#Positively Skewed. 3 seems to be the most common quantity for orders\n\n\n#Check discounts?\nrange(raw_sales_data$Discount)\n\n[1] 0.0 0.7\n\n#highest Discount we gave was 70% off\n\nraw_sales_data %&gt;% \n  ggplot(aes(x = Discount)) +\n  geom_histogram()\n\n\n\n#As expected, highest count was zero for discount, since not all the time we are giving off discount\n\n\n#Check profit\nsummary(raw_sales_data$Profit)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-1862.312   -12.849     7.775     8.699    33.727  1013.127 \n\n#For profit -- we have negative profit, average is 8 USD while max is at 1013.127 USD"
  },
  {
    "objectID": "projects/store_sales_modelling/sales_analysis.html#is-there-a-trend-or-seasonal-pattern-for-negative-and-positive-profit",
    "href": "projects/store_sales_modelling/sales_analysis.html#is-there-a-trend-or-seasonal-pattern-for-negative-and-positive-profit",
    "title": "Stores Sales",
    "section": "Is there a trend or seasonal pattern for Negative and Positive Profit?",
    "text": "Is there a trend or seasonal pattern for Negative and Positive Profit?\n\n#Lets use our time data\n\ntimed_profit_data = raw_sales_data %&gt;% \n  group_by(`Order Date`) %&gt;% \n  reframe(\n    Profit = sum(Profit,na.rm = TRUE)\n  )\n\ntimed_profit_data %&gt;% \n  ggplot(aes(x = `Order Date`,y = Profit,group = 1)) +\n  geom_line()\n\n\n\n#Ok looks like we already have a stationary data here interms of time series. Its also worth noticing how we have larger profit \n#dips compared to profit spike. Let's take a look.\n\ntimed_profit_data = timed_profit_data %&gt;% \n  mutate(\n    Gain_Loss = ifelse(Profit &lt;=0,\"Loss\",\"Gain\")\n  )\n\ntimed_profit_data %&gt;% \n  count(Gain_Loss)\n\n# A tibble: 2 × 2\n  Gain_Loss     n\n  &lt;chr&gt;     &lt;int&gt;\n1 Gain        560\n2 Loss        329\n\n#37% of our profit turns out to be negative. What is the trend for this value?\n\ntimed_profit_data %&gt;% \n  filter(Gain_Loss == \"Loss\") %&gt;% \n  ggplot(aes(x = `Order Date`,y = Profit)) +\n  geom_point() +\n  geom_line() \n\n\n\nraw_sales_data = raw_sales_data %&gt;% \n  mutate(\n    Gain_Loss = ifelse(Profit &lt;=0,\"Loss\",\"Gain\")\n  )\n\ngain_loss_count = raw_sales_data %&gt;% \n  group_by(`Order Date`,Gain_Loss) %&gt;% \n  reframe(\n    n = n()\n  )\n\ngain_loss_count %&gt;% \n  filter(Gain_Loss == \"Loss\") %&gt;% \n  ggplot(aes(x = `Order Date`,y = n)) +\n  geom_line()\n\n\n\n#Lets try to look at it at monthly basis?\nraw_sales_data = raw_sales_data %&gt;% \n  mutate(\n    Month = format(`Order Date`,\"%B\"),\n    Year = format(`Order Date`,\"%Y\"),\n    Month_Year = paste(Month,Year,sep = \"-\")\n  )\n\nmonth_profit_data = raw_sales_data %&gt;% \n  group_by(Month_Year, Gain_Loss) %&gt;% \n  reframe(\n    n = n()\n  ) %&gt;% \n  mutate(\n    Month_Year = paste(Month_Year,\"01\",sep = \"-\"),\n    Month_Year = as.Date(Month_Year,\"%B-%Y-%d\")\n  )\n  \nmonth_profit_data %&gt;% \n  filter(Gain_Loss == \"Loss\") %&gt;% \n  ggplot(aes(x = Month_Year, y = n, group = 1)) +\n  geom_point() +\n  geom_line()\n\n\n\n\nInteresting, Just by looking at it, it seems like the number of negative profits we have per month has a trend and seasonality. Best way to check it is to try to extract the time series components of our data.\n\nmonthly_loss = month_profit_data %&gt;% \n  filter(Gain_Loss == \"Loss\") %&gt;% \n  select(-Gain_Loss)\n\nts_loss = ts(monthly_loss$n,start = c(2014,01),frequency = 12)\nplot(ts_loss)\n\n\n\ndecompose(ts_loss) %&gt;% plot()\n\n\n\n\nLooks like our hunch is correct, we have a seasonal data on our hand. Looking at the seasonal component, it seems like that we usually experience a high count of Loss in profit at the end of the year. This could be attributed to end of year sale we usually implement.\nLets try to look the gain side of the data. See if we can spot a trend or seasonality as well\n\nmonthly_gain = month_profit_data %&gt;% \n  filter(Gain_Loss == \"Gain\") %&gt;% \n  select(-Gain_Loss)\n\nts_gain = ts(monthly_gain$n,start = c(2014,01),frequency = 12)\nplot(ts_gain)\n\n\n\ndecompose(ts_gain) %&gt;% plot()\n\n\n\n\nLooks like we have a better seasonality pattern here on our Gain Side for profit.\n\ngen_monthly_profit = raw_sales_data %&gt;% \n  group_by(Month_Year) %&gt;% \n  reframe(\n    Profit = sum(Profit)\n  ) %&gt;% \n  mutate(\n    Month_Year = paste(Month_Year,\"01\",sep = \"-\"),\n    Month_Year = as.Date(Month_Year,\"%B-%Y-%d\")\n  )\n  \ngen_monthly_profit %&gt;% \n  ggplot(aes(x = Month_Year, y = Profit)) +\n  geom_point() +\n  geom_line()\n\n\n\n#Check if there is a trend or seasonality??\n\nts_gen_profit_month = ts(gen_monthly_profit$Profit,start = c(\"2014\",\"01\"),frequency = 12)\n\ndecompose(ts_gen_profit_month) %&gt;% plot()\n\n\n\n#November appears to be the month we have the highest sale for each year and June to have the lowest sale."
  },
  {
    "objectID": "projects/store_sales_modelling/sales_analysis.html#section",
    "href": "projects/store_sales_modelling/sales_analysis.html#section",
    "title": "Stores Sales",
    "section": "",
    "text": "#Lets check the number of orders, and see if there is seasonality on the count as well\n\nmonthly_data_items = raw_sales_data %&gt;% \n  group_by(Month_Year) %&gt;% \n  reframe(\n    Quantity = sum(Quantity,na.rm = TRUE)\n  )%&gt;% \n  mutate(\n    Month_Year = paste(Month_Year,\"01\",sep = \"-\"),\n    Month_Year = as.Date(Month_Year,\"%B-%Y-%d\")\n  )\n  \nmonthly_data_items %&gt;% \n  ggplot(aes(x = Month_Year,y = Quantity,group = 1)) +\n  geom_point() +\n  geom_line()\n\n\n\n#Lets create a TS Object and try to decompose time series components\n\nts_quantity = ts(monthly_data_items$Quantity, start = c(\"2014\",\"01\"),frequency = 12)\n\ndecomposed_ts = decompose(ts_quantity)\nplot(decomposed_ts)"
  },
  {
    "objectID": "projects/store_sales_modelling/sales_analysis.html#arima-prophet-and-glm",
    "href": "projects/store_sales_modelling/sales_analysis.html#arima-prophet-and-glm",
    "title": "Stores Sales",
    "section": "ARIMA, Prophet and GLM",
    "text": "ARIMA, Prophet and GLM\nWe will build 3 time series models and compare which of these 3 models will perform the best.\nLets create 2 data frames and 2 Splits Object for our Time Series Model.\n\nmonthly_sales = raw_sales_data %&gt;% \n  group_by(Month_Year) %&gt;% \n  reframe(\n    Sales = sum(Sales, na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Month_Year = paste(Month_Year,\"01\",sep = \"-\"),\n    Month_Year = as.Date(Month_Year,\"%B-%Y-%d\")\n  )\n\nmonthly_quantity = raw_sales_data %&gt;% \n  group_by(Month_Year) %&gt;% \n  reframe(\n    Quantity = sum(Quantity, na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Month_Year = paste(Month_Year,\"01\",sep = \"-\"),\n    Month_Year = as.Date(Month_Year,\"%B-%Y-%d\")\n  )\n\nsales_split = time_series_split(\n  monthly_sales,\n  assess = \"6 months\",\n  cumulative = TRUE\n)\n\nquantity_split = time_series_split(\n  monthly_quantity,\n  assess = \"6 months\",\n  cumulative = TRUE\n)\n\n\nARIMA\n\nSales Forecast\n\n#View the partition using time series plot\nsales_split %&gt;% \n  tk_time_series_cv_plan() %&gt;% \n  plot_time_series_cv_plan(Month_Year,Sales)\n\n\n\n\nmodel_arima_sales = arima_reg() %&gt;% \n  set_engine(\"auto_arima\") %&gt;% \n  fit(Sales ~ Month_Year, training(sales_split))\n\nmodel_arima_sales\n\nparsnip model object\n\nSeries: outcome \nARIMA(0,0,0)(0,1,1)[12] with drift \n\nCoefficients:\n         sma1     drift\n      -0.5646  120.1691\ns.e.   0.3715   43.5067\n\nsigma^2 = 14370932:  log likelihood = -290.92\nAIC=587.83   AICc=588.76   BIC=592.04\n\n\n\n\nQuantity Forecast\n\n#View the partition using time series plot\nquantity_split %&gt;% \n  tk_time_series_cv_plan() %&gt;% \n  plot_time_series_cv_plan(Month_Year,Quantity)\n\n\n\n\nmodel_arima_quantity = arima_reg() %&gt;% \n  set_engine(\"auto_arima\") %&gt;% \n  fit(Quantity ~ Month_Year, training(quantity_split))\n\nmodel_arima_quantity\n\nparsnip model object\n\nSeries: outcome \nARIMA(0,0,0)(1,1,0)[12] with drift \n\nCoefficients:\n         sar1   drift\n      -0.6634  1.7887\ns.e.   0.1491  0.2807\n\nsigma^2 = 681.5:  log likelihood = -142.88\nAIC=291.76   AICc=292.68   BIC=295.96\n\n\n\n\n\nProphet\n\nSales Forecast\n\nmodel_prophet_sales = prophet_reg(seasonality_yearly = TRUE) %&gt;% \n  set_engine(\"prophet\") %&gt;% \n  fit(Sales ~ Month_Year, training(sales_split))\n\nmodel_prophet_sales\n\nparsnip model object\n\nPROPHET Model\n- growth: 'linear'\n- n.changepoints: 25\n- changepoint.range: 0.8\n- yearly.seasonality: 'TRUE'\n- weekly.seasonality: 'auto'\n- daily.seasonality: 'auto'\n- seasonality.mode: 'additive'\n- changepoint.prior.scale: 0.05\n- seasonality.prior.scale: 10\n- holidays.prior.scale: 10\n- logistic_cap: NULL\n- logistic_floor: NULL\n- extra_regressors: 0\n\n\n\n\nQuantity Forecast\n\nmodel_prophet_quantity = prophet_reg(seasonality_yearl = TRUE) %&gt;% \n  set_engine(\"prophet\") %&gt;% \n  fit(Quantity ~ Month_Year, training(quantity_split))\n\nmodel_prophet_quantity\n\nparsnip model object\n\nPROPHET Model\n- growth: 'linear'\n- n.changepoints: 25\n- changepoint.range: 0.8\n- yearly.seasonality: 'TRUE'\n- weekly.seasonality: 'auto'\n- daily.seasonality: 'auto'\n- seasonality.mode: 'additive'\n- changepoint.prior.scale: 0.05\n- seasonality.prior.scale: 10\n- holidays.prior.scale: 10\n- logistic_cap: NULL\n- logistic_floor: NULL\n- extra_regressors: 0\n\n\n\n\n\nGLM\n\nSales Forecast\n\n# On this model, we try to add components of a our data object as our predictor.\nmodel_glmnet_sales = linear_reg(penalty = 0.01) %&gt;% \n  set_engine(\"glmnet\") %&gt;% \n  fit(\n    Sales ~ lubridate::month(Month_Year, label = TRUE) +\n      as.numeric(Month_Year),\n    training(sales_split)\n  )\n\n\n\nQuantity Forecast\n\nmodel_glmnet_quantity = linear_reg(penalty = 0.01) %&gt;% \n  set_engine(\"glmnet\") %&gt;% \n  fit(\n    Quantity ~ lubridate::month(Month_Year, label = TRUE) +\n      as.numeric(Month_Year),\n    training(quantity_split)\n  )\n\n\n\n\nModel Evaluation\nWe will consolidate our 3 models into one object and for comparison and evaluation.\n\nSales Forecast Evaluation\n\n#Create Calibration table\nmodel_tbl_sales = modeltime_table(\n  model_arima_sales,\n  model_prophet_sales,\n  model_glmnet_sales\n)\n\ncalib_tbl_sales = model_tbl_sales %&gt;% \n  modeltime_calibrate(testing(sales_split))\n\n\ncalib_tbl_sales %&gt;% modeltime_accuracy() %&gt;% \n  select(`.model_id`,`.model_desc`,rmse,rsq)\n\n# A tibble: 3 × 4\n  .model_id .model_desc                         rmse   rsq\n      &lt;int&gt; &lt;chr&gt;                              &lt;dbl&gt; &lt;dbl&gt;\n1         1 ARIMA(0,0,0)(0,1,1)[12] WITH DRIFT 4200. 0.816\n2         2 PROPHET                            4661. 0.789\n3         3 GLMNET                             4272. 0.818\n\n\nthe modeltime_accuracy() can show us multiple accuracy metrics for our Sales Forecast Models. But for the purpose of our project, we will only select the model_id, model_desc, rmse and rsq (R-squared).\nOn the script below, we will see how the 3 model performs in comparison with our testing dataset.\n\ncalib_tbl_sales %&gt;% \n  modeltime_forecast(\n    new_data = testing(sales_split),\n    actual_data = monthly_sales\n  ) %&gt;% \n  plot_modeltime_forecast()\n\n\n\n\n\nWe will then use the model to generate our 6 months forecast and plot it.\n\nfuture_forecast_tbl_sales = calib_tbl_sales %&gt;% \n  modeltime_refit(monthly_sales) %&gt;% \n  modeltime_forecast(\n    h = \"6 months\",\n    actual_data = monthly_sales\n  )\n\nfuture_forecast_tbl_sales %&gt;% \n  plot_modeltime_forecast()\n\n\n\n\n\nLet’s repeat the process for Quantity Prediction.\n\n#Create Calibration table\nmodel_tbl_quantity = modeltime_table(\n  model_arima_quantity,\n  model_prophet_quantity,\n  model_glmnet_quantity\n)\n\ncalib_tbl_quantity = model_tbl_quantity %&gt;% \n  modeltime_calibrate(testing(quantity_split))\n\n\ncalib_tbl_quantity %&gt;% modeltime_accuracy() %&gt;% \n  select(`.model_id`,`.model_desc`,rmse,rsq)\n\n# A tibble: 3 × 4\n  .model_id .model_desc                         rmse   rsq\n      &lt;int&gt; &lt;chr&gt;                              &lt;dbl&gt; &lt;dbl&gt;\n1         1 ARIMA(0,0,0)(1,1,0)[12] WITH DRIFT  42.8 0.895\n2         2 PROPHET                             36.4 0.953\n3         3 GLMNET                              39.1 0.943\n\n\n\ncalib_tbl_quantity %&gt;% \n  modeltime_forecast(\n    new_data = testing(quantity_split),\n    actual_data = monthly_quantity\n  ) %&gt;% \n  plot_modeltime_forecast()\n\n\n\n\n\n\nfuture_forecast_tbl_quantity = calib_tbl_quantity %&gt;% \n  modeltime_refit(monthly_quantity) %&gt;% \n  modeltime_forecast(\n    h = \"6 months\",\n    actual_data = monthly_quantity\n  )\nfuture_forecast_tbl_quantity %&gt;% \n  plot_modeltime_forecast()"
  },
  {
    "objectID": "projects/store_sales_modelling/sales_analysis.html#conclusion",
    "href": "projects/store_sales_modelling/sales_analysis.html#conclusion",
    "title": "Stores Sales",
    "section": "Conclusion",
    "text": "Conclusion\nAfter using 3 different Forecast Model, we can safely say that Prophet and GLM model outperformed ARIMA model. Both Prophet and GLM was able to capture the seasonality the variation of the original data. ARIMA’s forecast on Sales Data is a straight line only which for us won’t make much of sense in a real-life setting."
  },
  {
    "objectID": "projects/Livestock/livestock.html",
    "href": "projects/Livestock/livestock.html",
    "title": "Livestock Pattern Analysis",
    "section": "",
    "text": "We are going to analyze the Livestock data downloaded from Food and Agriculture Organization of the United Nations website. Below are the questions we are going to answer by using our data.\n\nWhat Items or Livestock has the highest density for the most recent year by:\n\nOverall (World wide)\nRegion\n\nWhat is the trend of total Livestock density for:\n\nOverall\nRegion\n\nIdentify if there is a significant difference in Livestock Density for each Region.\nDetermine the Top 10 country with the Highest Livestock Density.\nCreate a Time Series Model for:\n\nThe top 3 Livestock Product of the Top 1 Country by Livestock Density for each Region"
  },
  {
    "objectID": "projects/Livestock/livestock.html#overview",
    "href": "projects/Livestock/livestock.html#overview",
    "title": "Livestock Pattern Analysis",
    "section": "",
    "text": "We are going to analyze the Livestock data downloaded from Food and Agriculture Organization of the United Nations website. Below are the questions we are going to answer by using our data.\n\nWhat Items or Livestock has the highest density for the most recent year by:\n\nOverall (World wide)\nRegion\n\nWhat is the trend of total Livestock density for:\n\nOverall\nRegion\n\nIdentify if there is a significant difference in Livestock Density for each Region.\nDetermine the Top 10 country with the Highest Livestock Density.\nCreate a Time Series Model for:\n\nThe top 3 Livestock Product of the Top 1 Country by Livestock Density for each Region"
  },
  {
    "objectID": "projects/Livestock/livestock.html#data-import-and-pre-process",
    "href": "projects/Livestock/livestock.html#data-import-and-pre-process",
    "title": "Livestock Pattern Analysis",
    "section": "Data Import and Pre-Process",
    "text": "Data Import and Pre-Process\n\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(countrycode)\nlibrary(FSA)\nlibrary(forecast)\n\nlivestock_data = fread(\"Livestock_data.csv\") %&gt;% as_tibble()\n\n\n#Check Dimension of Data\nglimpse(livestock_data)\n\nRows: 8,180\nColumns: 70\n$ `Area Code`       &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ `Area Code (M49)` &lt;chr&gt; \"'004\", \"'004\", \"'004\", \"'004\", \"'004\", \"'004\", \"'00…\n$ Area              &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghan…\n$ `Item Code`       &lt;int&gt; 1107, 1107, 1107, 1126, 1126, 1126, 866, 866, 866, 1…\n$ `Item Code (CPC)` &lt;chr&gt; \"'02132\", \"'02132\", \"'02132\", \"'02121.01\", \"'02121.0…\n$ Item              &lt;chr&gt; \"Asses\", \"Asses\", \"Asses\", \"Camels\", \"Camels\", \"Came…\n$ `Element Code`    &lt;int&gt; 7213, 7211, 5118, 7213, 7211, 5118, 7213, 7211, 5118…\n$ Element           &lt;chr&gt; \"Livestock units per agricultural land area\", \"Share…\n$ Unit              &lt;chr&gt; \"LSU/ha\", \"%LSU\", \"LSU\", \"LSU/ha\", \"%LSU\", \"LSU\", \"L…\n$ Y1961             &lt;dbl&gt; 0.02, 12.36, 650000.00, 0.00, 3.57, 187500.00, 0.05,…\n$ Y1962             &lt;dbl&gt; 0.01, 8.10, 425925.00, 0.01, 3.99, 209932.50, 0.06, …\n$ Y1963             &lt;dbl&gt; 0.01, 9.15, 500556.00, 0.01, 4.79, 262053.75, 0.06, …\n$ Y1964             &lt;dbl&gt; 0.02, 10.27, 575000.00, 0.01, 4.35, 243750.00, 0.06,…\n$ Y1965             &lt;dbl&gt; 2.000e-02, 1.134e+01, 6.500e+05, 1.000e-02, 3.920e+0…\n$ Y1966             &lt;dbl&gt; 2.000e-02, 1.016e+01, 6.000e+05, 1.000e-02, 3.810e+0…\n$ Y1967             &lt;dbl&gt; 2.000e-02, 1.014e+01, 6.000e+05, 1.000e-02, 3.800e+0…\n$ Y1968             &lt;dbl&gt; 0.02, 10.84, 664000.00, 0.01, 3.66, 224250.00, 0.07,…\n$ Y1969             &lt;dbl&gt; 2.000e-02, 1.033e+01, 6.250e+05, 1.000e-02, 3.720e+0…\n$ Y1970             &lt;dbl&gt; 2.000e-02, 1.051e+01, 6.500e+05, 1.000e-02, 3.640e+0…\n$ Y1971             &lt;dbl&gt; 2.000e-02, 1.057e+01, 6.500e+05, 1.000e-02, 3.660e+0…\n$ Y1972             &lt;dbl&gt; 2.000e-02, 1.309e+01, 6.500e+05, 1.000e-02, 4.530e+0…\n$ Y1973             &lt;dbl&gt; 0.02, 12.06, 625000.00, 0.01, 4.34, 225000.00, 0.06,…\n$ Y1974             &lt;dbl&gt; 0.02, 11.26, 625000.00, 0.01, 4.05, 225000.00, 0.06,…\n$ Y1975             &lt;dbl&gt; 0.02, 10.48, 625000.00, 0.01, 3.77, 225000.00, 0.07,…\n$ Y1976             &lt;dbl&gt; 2.000e-02, 1.027e+01, 6.250e+05, 1.000e-02, 3.700e+0…\n$ Y1977             &lt;dbl&gt; 0.02, 10.84, 650000.00, 0.01, 3.75, 225000.00, 0.07,…\n$ Y1978             &lt;dbl&gt; 0.02, 10.95, 650000.00, 0.01, 3.79, 225000.00, 0.07,…\n$ Y1979             &lt;dbl&gt; 2.000e-02, 1.117e+01, 6.500e+05, 1.000e-02, 3.480e+0…\n$ Y1980             &lt;dbl&gt; 0.02, 11.08, 647500.00, 0.01, 3.40, 198750.00, 0.07,…\n$ Y1981             &lt;dbl&gt; 0.02, 11.13, 657500.00, 0.01, 3.36, 198750.00, 0.07,…\n$ Y1982             &lt;dbl&gt; 0.02, 11.14, 657500.00, 0.01, 3.37, 198750.00, 0.07,…\n$ Y1983             &lt;dbl&gt; 0.02, 11.93, 657500.00, 0.01, 3.60, 198750.00, 0.06,…\n$ Y1984             &lt;dbl&gt; 0.02, 13.91, 659000.00, 0.01, 4.20, 198750.00, 0.05,…\n$ Y1985             &lt;dbl&gt; 0.02, 15.60, 660500.00, 0.01, 4.69, 198750.00, 0.04,…\n$ Y1986             &lt;dbl&gt; 0.02, 19.31, 662500.00, 0.01, 5.79, 198750.00, 0.03,…\n$ Y1987             &lt;dbl&gt; 2.000e-02, 1.777e+01, 6.500e+05, 1.000e-02, 6.150e+0…\n$ Y1988             &lt;dbl&gt; 0.01, 13.37, 500000.00, 0.01, 5.32, 198750.00, 0.03,…\n$ Y1989             &lt;dbl&gt; 0.01, 10.98, 400000.00, 0.00, 4.84, 176250.00, 0.03,…\n$ Y1990             &lt;dbl&gt; 0.01, 8.43, 300000.00, 0.00, 4.53, 161250.00, 0.03, …\n$ Y1991             &lt;dbl&gt; 1.000e-02, 7.080e+00, 2.500e+05, 0.000e+00, 4.250e+0…\n$ Y1992             &lt;dbl&gt; 1.000e-02, 7.060e+00, 2.500e+05, 0.000e+00, 4.230e+0…\n$ Y1993             &lt;dbl&gt; 1.000e-02, 7.030e+00, 2.500e+05, 0.000e+00, 4.220e+0…\n$ Y1994             &lt;dbl&gt; 1.000e-02, 8.170e+00, 3.000e+05, 0.000e+00, 4.090e+0…\n$ Y1995             &lt;dbl&gt; 0.01, 9.06, 352000.00, 0.00, 3.88, 150750.00, 0.04, …\n$ Y1996             &lt;dbl&gt; 0.01, 8.59, 376500.00, 0.00, 3.78, 165750.00, 0.05, …\n$ Y1997             &lt;dbl&gt; 0.01, 8.37, 402500.00, 0.00, 3.77, 181500.00, 0.05, …\n$ Y1998             &lt;dbl&gt; 0.01, 8.34, 430000.00, 0.01, 3.86, 198750.00, 0.06, …\n$ Y1999             &lt;dbl&gt; 0.01, 8.00, 459970.00, 0.01, 3.79, 217788.00, 0.06, …\n$ Y2000             &lt;dbl&gt; 1.000e-02, 6.930e+00, 3.410e+05, 0.000e+00, 3.410e+0…\n$ Y2001             &lt;dbl&gt; 0.01, 8.26, 341000.00, 0.00, 4.07, 168000.00, 0.04, …\n$ Y2002             &lt;dbl&gt; 0.02, 14.91, 794000.00, 0.00, 2.47, 131250.00, 0.07,…\n$ Y2003             &lt;dbl&gt; 0.02, 14.63, 799000.00, 0.00, 2.49, 135750.00, 0.07,…\n$ Y2004             &lt;dbl&gt; 0.02, 14.99, 807000.00, 0.00, 2.65, 142500.00, 0.06,…\n$ Y2005             &lt;dbl&gt; 0.02, 12.79, 695500.00, 0.00, 2.59, 141000.00, 0.07,…\n$ Y2006             &lt;dbl&gt; 2.000e-02, 1.126e+01, 6.075e+05, 0.000e+00, 2.420e+0…\n$ Y2007             &lt;dbl&gt; 0.02, 13.54, 736000.00, 0.00, 2.57, 139500.00, 0.08,…\n$ Y2008             &lt;dbl&gt; 0.02, 10.14, 604500.00, 0.00, 2.30, 137250.00, 0.09,…\n$ Y2009             &lt;dbl&gt; 0.02, 10.83, 661000.00, 0.00, 2.33, 142500.00, 0.09,…\n$ Y2010             &lt;dbl&gt; 0.02, 9.97, 702500.00, 0.00, 2.03, 143250.00, 0.10, …\n$ Y2011             &lt;dbl&gt; 0.02, 10.27, 733000.00, 0.00, 1.81, 129000.00, 0.10,…\n$ Y2012             &lt;dbl&gt; 0.02, 10.40, 711500.00, 0.00, 1.91, 130500.00, 0.10,…\n$ Y2013             &lt;dbl&gt; 0.02, 10.77, 725500.00, 0.00, 1.89, 127500.00, 0.10,…\n$ Y2014             &lt;dbl&gt; 0.02, 10.53, 720500.00, 0.00, 1.87, 128250.00, 0.10,…\n$ Y2015             &lt;dbl&gt; 0.02, 10.81, 740500.00, 0.00, 1.86, 127500.00, 0.10,…\n$ Y2016             &lt;dbl&gt; 0.02, 10.82, 736050.00, 0.00, 1.88, 127875.00, 0.10,…\n$ Y2017             &lt;dbl&gt; 0.02, 9.92, 658500.00, 0.00, 1.94, 129000.00, 0.09, …\n$ Y2018             &lt;dbl&gt; 0.02, 10.01, 682038.97, 0.00, 1.89, 129068.99, 0.09,…\n$ Y2019             &lt;dbl&gt; 0.02, 11.44, 781841.65, 0.00, 1.87, 127661.06, 0.09,…\n$ Y2020             &lt;dbl&gt; 0.02, 11.37, 771299.07, 0.00, 1.88, 127474.37, 0.09,…\n$ Y2021             &lt;dbl&gt; 0.02, 11.47, 780882.17, 0.00, 1.87, 126964.23, 0.09,…\n\n#8180 rows and 70 Columns\n\n\n\n\n\n\n\nNote\n\n\n\nData Dictionary\n\nArea Code = Code for the Country\nArea Code (M49) = Standard Country or Area Code for Statistical Use\nArea = Country Name\nItem Code = Code for Livestock Product/Item\nItem Code (CPC)= Customs Procedure Code to determine if product is for Import or Export\nItem = Name of livestock product\nElement = Unit of measurement for Livestock\nElement Code = Numeric code for Livestock Unit of Measurement\nUnit = Shorthand notation or symbol of Element Column\nY&lt;9999&gt; = Year\n\n\n\nWe need to add a region column for us to answer some of the questions on our list above.\n\nlivestock_data = livestock_data %&gt;% \n  mutate(\n    Region = countrycode(\n      sourcevar = Area,\n      origin = \"country.name\",\n      destination = \"continent\"\n    )\n  ) %&gt;% \n  filter(\n    !is.na(Region)\n  )\n\nWarning: There were 737 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `Region = countrycode(sourcevar = Area, origin = \"country.name\",\n  destination = \"continent\")`.\nCaused by warning in `grepl()`:\n! input string 1 is invalid UTF-8\nℹ Run `dplyr::last_dplyr_warnings()` to see the 736 remaining warnings.\n\nhead(livestock_data)\n\n# A tibble: 6 × 71\n  `Area Code` `Area Code (M49)` Area        `Item Code` `Item Code (CPC)` Item  \n        &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;             &lt;int&gt; &lt;chr&gt;             &lt;chr&gt; \n1           2 '004              Afghanistan        1107 '02132            Asses \n2           2 '004              Afghanistan        1107 '02132            Asses \n3           2 '004              Afghanistan        1107 '02132            Asses \n4           2 '004              Afghanistan        1126 '02121.01         Camels\n5           2 '004              Afghanistan        1126 '02121.01         Camels\n6           2 '004              Afghanistan        1126 '02121.01         Camels\n# ℹ 65 more variables: `Element Code` &lt;int&gt;, Element &lt;chr&gt;, Unit &lt;chr&gt;,\n#   Y1961 &lt;dbl&gt;, Y1962 &lt;dbl&gt;, Y1963 &lt;dbl&gt;, Y1964 &lt;dbl&gt;, Y1965 &lt;dbl&gt;,\n#   Y1966 &lt;dbl&gt;, Y1967 &lt;dbl&gt;, Y1968 &lt;dbl&gt;, Y1969 &lt;dbl&gt;, Y1970 &lt;dbl&gt;,\n#   Y1971 &lt;dbl&gt;, Y1972 &lt;dbl&gt;, Y1973 &lt;dbl&gt;, Y1974 &lt;dbl&gt;, Y1975 &lt;dbl&gt;,\n#   Y1976 &lt;dbl&gt;, Y1977 &lt;dbl&gt;, Y1978 &lt;dbl&gt;, Y1979 &lt;dbl&gt;, Y1980 &lt;dbl&gt;,\n#   Y1981 &lt;dbl&gt;, Y1982 &lt;dbl&gt;, Y1983 &lt;dbl&gt;, Y1984 &lt;dbl&gt;, Y1985 &lt;dbl&gt;,\n#   Y1986 &lt;dbl&gt;, Y1987 &lt;dbl&gt;, Y1988 &lt;dbl&gt;, Y1989 &lt;dbl&gt;, Y1990 &lt;dbl&gt;, …\n\n\nNow that we have our Region/Continent column we can start answering our questions from the list above"
  },
  {
    "objectID": "projects/Livestock/livestock.html#questions",
    "href": "projects/Livestock/livestock.html#questions",
    "title": "Livestock Pattern Analysis",
    "section": "Questions",
    "text": "Questions\n\nHighest Livestock Density\n\nOverall\n\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  group_by(Item) %&gt;% \n  reframe(\n    Livestock_Density = sum(Y2021, na.rm = TRUE)\n  ) %&gt;% \n  arrange(desc(Livestock_Density)) %&gt;% \n  top_n(10) %&gt;% \n  mutate(\n    Item = reorder(Item, Livestock_Density)\n  ) %&gt;% \n  ggplot(aes(x = Item, y = Livestock_Density)) +\n  geom_col()+\n  coord_flip()\n\n\n\n\n\nRegion\n\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  group_by(Region, Item) %&gt;% \n  reframe(\n    Livestock_Density = sum(Y2021, na.rm = TRUE)\n  ) %&gt;% \n  arrange(desc(Livestock_Density)) %&gt;% \n  #top_n(10) %&gt;% \n  mutate(\n    Region = reorder(Region, Livestock_Density)\n  ) %&gt;% \n  ggplot(aes(x = Region, y = Livestock_Density, fill = Item)) +\n  geom_col()+\n  coord_flip()\n\n\n\n\n\n\nLivestock Density Trend\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  pivot_longer(-c(1:9,71),names_to = \"Year\", values_to = \"Livestock_Density\") %&gt;% \n  group_by(Year) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density,na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Year = str_remove(Year, \"Y\"),\n    Year = paste(Year,\"01\",\"01\",sep = \"-\"),\n    Year = as.Date(Year)\n  ) %&gt;% \n  ggplot(aes(x = Year, Livestock_Density,group = 1)) +\n  geom_point()+\n  geom_line()\n\n\n\n\nInteresting. There is a sharp dip of Total Livestock Density in Worldwide Level. Let’s investigate this further\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  pivot_longer(-c(1:9,71),names_to = \"Year\", values_to = \"Livestock_Density\") %&gt;% \n  group_by(Year) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density,na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Year = str_remove(Year, \"Y\"),\n    Year = paste(Year,\"01\",\"01\",sep = \"-\"),\n    Year = as.Date(Year)\n  ) %&gt;% \n  slice(which.min(Livestock_Density))\n\n# A tibble: 1 × 2\n  Year       Livestock_Density\n  &lt;date&gt;                 &lt;dbl&gt;\n1 1961-01-01              248.\n\n\nThe year where we saw the sharp dip is 1961. Let’s see what happen on this year by splicing the Livestock computation by region. Maybe we can see a region dropping its Livestock, or maybe we can see that all region will have a sharp dip.\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  pivot_longer(-c(1:9,71),names_to = \"Year\", values_to = \"Livestock_Density\") %&gt;% \n  group_by(Region,Year) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density,na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Year = str_remove(Year, \"Y\"),\n    Year = paste(Year,\"01\",\"01\",sep = \"-\"),\n    Year = as.Date(Year)\n  ) %&gt;% \n  ggplot(aes(x = Year, Livestock_Density,group = Region, color = Region)) +\n  geom_point()+\n  geom_line()\n\n\n\n\nAsia seems to be the driver of that sharp dip we saw from the world level. Lets try to remove Asia from the graph. Looking at the visual, there seems to be a drop on other continent as well. The scale of Asia’s Livestock density is making the trend on other continents seem small.\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  pivot_longer(-c(1:9,71),names_to = \"Year\", values_to = \"Livestock_Density\") %&gt;% \n  filter(Region != \"Asia\") %&gt;% \n  group_by(Region,Year) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density,na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Year = str_remove(Year, \"Y\"),\n    Year = paste(Year,\"01\",\"01\",sep = \"-\"),\n    Year = as.Date(Year)\n  ) %&gt;% \n  ggplot(aes(x = Year, Livestock_Density,group = Region, color = Region)) +\n  geom_point()+\n  geom_line()\n\n\n\n\nLooks like Asia is really the one causing the dip. Let’s try to look at this one level lower.\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  pivot_longer(-c(1:9,71),names_to = \"Year\", values_to = \"Livestock_Density\") %&gt;% \n  filter(Region == \"Asia\") %&gt;% \n  group_by(Area,Year) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density,na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Year = str_remove(Year, \"Y\"),\n    Year = paste(Year,\"01\",\"01\",sep = \"-\"),\n    Year = as.Date(Year)\n  ) %&gt;% \n  ggplot(aes(x = Year, Livestock_Density,group = Area, color = Area)) +\n  geom_point(show.legend = FALSE)+\n  geom_line(show.legend = FALSE)\n\n\n\n\nIt is hard to identify what country is displaying the sharp dip for 1991. Lets do it using dplyr\n\ndip_country = livestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  pivot_longer(-c(1:9,71),names_to = \"Year\", values_to = \"Livestock_Density\") %&gt;% \n  filter(Region == \"Asia\") %&gt;% \n  group_by(Area,Year) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density,na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Year = str_remove(Year, \"Y\"),\n    Year = paste(Year,\"01\",\"01\",sep = \"-\"),\n    Year = as.Date(Year)\n  ) \n\ndip_country %&gt;% \n  mutate(\n    LagDiff = c(0,diff(dip_country$Livestock_Density))\n  ) %&gt;% \n  filter(LagDiff &lt; 0) %&gt;% \n  filter(LagDiff &lt; -15)\n\n# A tibble: 5 × 4\n  Area                      Year       Livestock_Density LagDiff\n  &lt;chr&gt;                     &lt;date&gt;                 &lt;dbl&gt;   &lt;dbl&gt;\n1 Cambodia                  1961-01-01              1.23   -31.5\n2 China, Taiwan Province of 1961-01-01              2.98   -34.2\n3 Singapore                 1988-01-01             69.2    -29.2\n4 Singapore                 1991-01-01             34.1    -62.3\n5 Sri Lanka                 1961-01-01              2.14  -117. \n\n\nWe created a new column called LagDiff which is the result of calculating the difference of the current Livestock Density and its previous value. That way, we can see what year and country have the highest negative LagDiff that will indicate a sharp dip.\nLooking at the result, we see that its probably Singapore. Since Cambodia, China and Sri Lanka’s value are all from 1961 which is obviously not the year of Interest for us.\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  pivot_longer(-c(1:9,71),names_to = \"Year\", values_to = \"Livestock_Density\") %&gt;% \n  filter(Region == \"Asia\") %&gt;% \n  filter(Area == \"Singapore\") %&gt;% \n  group_by(Area,Year) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density,na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Year = str_remove(Year, \"Y\"),\n    Year = paste(Year,\"01\",\"01\",sep = \"-\"),\n    Year = as.Date(Year)\n  ) %&gt;% \n  ggplot(aes(x = Year, Livestock_Density,group = Area, color = Area)) +\n  geom_point(show.legend = FALSE)+\n  geom_line(show.legend = FALSE)\n\n\n\n\nSingapore is the country influencing the dip at year 1991. Doing a bit of research about this sharp drop, it turns out that the cause of this drop is due to Mt. Pinatubo’s volcanic eruption in the Philippines. Lets add the Philippines on our chart\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  pivot_longer(-c(1:9,71),names_to = \"Year\", values_to = \"Livestock_Density\") %&gt;% \n  filter(Region == \"Asia\") %&gt;% \n  filter(Area %in% c(\"Singapore\",\"Philippines\") ) %&gt;% \n  group_by(Area,Year) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density,na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Year = str_remove(Year, \"Y\"),\n    Year = paste(Year,\"01\",\"01\",sep = \"-\"),\n    Year = as.Date(Year)\n  ) %&gt;% \n  ggplot(aes(x = Year, Livestock_Density,group = Area, color = Area)) +\n  geom_point()+\n  geom_line()\n\n\n\n\nSingapore’s Livestock Density value is too high for us to see the variance in Ph’s data.\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  pivot_longer(-c(1:9,71),names_to = \"Year\", values_to = \"Livestock_Density\") %&gt;% \n  filter(Region == \"Asia\") %&gt;% \n  filter(Area %in% c(\"Philippines\") ) %&gt;% \n  group_by(Area,Year) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density,na.rm = TRUE)\n  ) %&gt;% \n  mutate(\n    Year = str_remove(Year, \"Y\"),\n    Year = paste(Year,\"01\",\"01\",sep = \"-\"),\n    Year = as.Date(Year)\n  ) %&gt;% \n  ggplot(aes(x = Year, Livestock_Density,group = Area, color = Area)) +\n  geom_point()+\n  geom_line()\n\n\n\n\nLooks like even before that year, the livestock density for Ph is already low, that’s why the decrease in livestock when Mt. Pinatubo erupted does not really cause much of change in Ph’s Livestock Density.\n\n\nRegion Significant Difference\n\nlivestock_by_region = livestock_data %&gt;% \n  group_by(Region) %&gt;% \n  reframe(\n    Livestock_Density = sum(Y2021, na.rm = TRUE)\n  )\n\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  ggplot(aes(x = Region, y = Y2021)) +\n  geom_boxplot()\n\n\n\n\nBefore we can use ANOVA check if there is a significant difference on Livestock Density for each Region, we need to determine first if the data on each group is normal.\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  filter(Region == \"Asia\") %&gt;% \n  filter(!is.na(Y2021)) %&gt;% \n  pull(Y2021) %&gt;% \n  shapiro.test()\n\n\n    Shapiro-Wilk normality test\n\ndata:  .\nW = 0.11448, p-value &lt; 2.2e-16\n\n\nAsia’s value for Livestock Density is not normal since we have a p.value of less than 0.05\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  filter(Region == \"Africa\") %&gt;% \n  filter(!is.na(Y2021)) %&gt;% \n  pull(Y2021) %&gt;% \n  shapiro.test()\n\n\n    Shapiro-Wilk normality test\n\ndata:  .\nW = 0.502, p-value &lt; 2.2e-16\n\n\nSame for Africa.\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  filter(Region == \"Europe\") %&gt;% \n  filter(!is.na(Y2021)) %&gt;% \n  pull(Y2021) %&gt;% \n  shapiro.test()\n\n\n    Shapiro-Wilk normality test\n\ndata:  .\nW = 0.50173, p-value &lt; 2.2e-16\n\n\nEurope is also not normal. At this point, we dont need to check the other 2 Region, since as pre ANOVA’s requirement, all group should come from a normal distribution. We can still determine if there is a significant difference among the groups by using a Non-Parametric approach. This approach will not require our data to come from a normal distribution.\n\nlivestock_region_data = livestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  filter(!is.na(Y2021)) %&gt;% \n  select(Region, Y2021)\n\nlivestock_kruskal = kruskal.test(Y2021 ~ Region, data = livestock_region_data )\nlivestock_kruskal\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Y2021 by Region\nKruskal-Wallis chi-squared = 35.535, df = 4, p-value = 3.606e-07\n\n\nWe have a p.value of less than 0.05 indicating that we have a significant difference in Livestock Density for each Region. But let us take the test further and identify which among these groups have a significant difference among each other. We will use Dunn’s test for this task.\n\ndunn_result = dunnTest(Y2021 ~ Region, data = livestock_region_data)\n\n#Let's filter out those comparison test with an adjusted p.value of greater than 0.05\n\n\ndunn_result$res %&gt;% \n  filter(P.adj &lt; 0.05)\n\n         Comparison         Z      P.unadj        P.adj\n1 Africa - Americas -4.484740 7.300273e-06 6.570246e-05\n2     Africa - Asia -4.106799 4.011807e-05 3.209446e-04\n3   Africa - Europe -3.235075 1.216108e-03 8.512756e-03\n4  Africa - Oceania -4.631136 3.636652e-06 3.636652e-05\n\n\nChecking the result from Dunn’s test, it seems that Africa have a significant difference on Livestock Desnity with all other Region in our data set.\n\n\nTop 10 Country with Highest Livestock Density\nWe can easily extract this information with a simple code using dplyr.\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  select(Area, Y2021) %&gt;% \n  filter(!is.na(Y2021)) %&gt;% \n  group_by(Area) %&gt;% \n  reframe(\n    Livestock_Density = sum(Y2021, na.rm = TRUE)\n  ) %&gt;% \n  arrange(desc(Livestock_Density)) %&gt;% \n  top_n(10)\n\n# A tibble: 10 × 2\n   Area                             Livestock_Density\n   &lt;chr&gt;                                        &lt;dbl&gt;\n 1 Singapore                                   119.  \n 2 China, Hong Kong SAR                         37.2 \n 3 Brunei Darussalam                            32.7 \n 4 Trinidad and Tobago                          16.4 \n 5 Barbados                                     13.1 \n 6 Micronesia (Federated States of)             10.8 \n 7 Republic of Korea                            10.7 \n 8 Kuwait                                       10.2 \n 9 Qatar                                        10.2 \n10 Netherlands (Kingdom of the)                  9.95\n\n\nWe can also check the top 10 for each Region and visualize it for better view.\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  filter(!is.na(Y2021)) %&gt;% \n  group_by(Region, Area) %&gt;% \n  summarise(\n    Livestock_Density = sum(Y2021, na.rm = TRUE)\n  ) %&gt;% \n  top_n(10) %&gt;% \n  ungroup() %&gt;% \n  mutate(\n    Area = reorder(Area, Livestock_Density)\n  ) %&gt;% \n  ggplot(aes(x = Area, y = Livestock_Density, fill = Region)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~Region, scales = \"free\") +\n  scale_x_discrete(label = function(x) abbreviate(x, minlength = 7)) +\n  coord_flip()\n\n\n\n\n\nlivestock_data %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  filter(!is.na(Y2021)) %&gt;% \n  group_by(Region, Area) %&gt;% \n  summarise(\n    Livestock_Density = sum(Y2021, na.rm = TRUE)\n  ) %&gt;% \n  top_n(10) %&gt;% \n  filter(Region == \"Africa\") %&gt;% \n  arrange(desc(Livestock_Density))\n\n`summarise()` has grouped output by 'Region'. You can override using the\n`.groups` argument.\nSelecting by Livestock_Density\n\n\n# A tibble: 10 × 3\n# Groups:   Region [1]\n   Region Area                     Livestock_Density\n   &lt;chr&gt;  &lt;chr&gt;                                &lt;dbl&gt;\n 1 Africa Seychelles                            4.3 \n 2 Africa Mauritius                             4.13\n 3 Africa Ethiopia                              3.68\n 4 Africa Egypt                                 3.67\n 5 Africa Burkina Faso                          2.13\n 6 Africa Kenya                                 2.13\n 7 Africa Guinea-Bissau                         2.1 \n 8 Africa Uganda                                2.04\n 9 Africa Cabo Verde                            1.98\n10 Africa Central African Republic              1.97\n\n\n\n\nTime Series Modelling\nLet’s start by creating a time series model for Africa’s highest Livestock Density Country, Seychelles\n\n#Let's identify first the top 3 Livestock Product for Seychelles\nlivestock_data %&gt;% \n  filter(Region == \"Africa\") %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  filter(Area == \"Seychelles\") %&gt;% \n  group_by(Item) %&gt;% \n  reframe(\n    Livestock_Density = sum(Y2021, na.rm = TRUE)\n  ) %&gt;% \n  arrange(desc(Livestock_Density))\n\n# A tibble: 7 × 2\n  Item                  Livestock_Density\n  &lt;chr&gt;                             &lt;dbl&gt;\n1 Major livestock types              1.92\n2 Chickens                           0.84\n3 Swine / pigs                       0.62\n4 Goats                              0.37\n5 Sheep and Goats                    0.37\n6 Cattle                             0.09\n7 Cattle and Buffaloes               0.09\n\n#Top 3 Livestock Item for Seychelles is Major Livestock Types, Chickens and Swine/Pigs\n\n\n#Lets Filter the Major Livestock Types first\nafrica_1 = livestock_data %&gt;% \n  filter(Region == \"Africa\") %&gt;% \n  filter(Element == \"Livestock units per agricultural land area\") %&gt;% \n  filter(Area == \"Seychelles\") %&gt;% \n  select(Area,Item,c(10:70)) %&gt;% \n  pivot_longer(-c(Area,Item),names_to = \"Year\", values_to = \"Livestock_Density\") %&gt;% \n   mutate(\n    Year = str_remove(Year, \"Y\"),\n    Year = paste(Year,\"01\",\"01\",sep = \"-\"),\n    Year = as.Date(Year)\n  ) %&gt;% \n  group_by(Area,Item, Year) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density, na.rm = TRUE)\n  )\n\n\nafrica_1 %&gt;% \n  group_by(Item) %&gt;% \n  reframe(\n    Livestock_Density = sum(Livestock_Density,na.rm = TRUE)\n  ) %&gt;% \n  arrange(desc(Livestock_Density))\n\n# A tibble: 7 × 2\n  Item                  Livestock_Density\n  &lt;chr&gt;                             &lt;dbl&gt;\n1 Major livestock types             91.2 \n2 Chickens                          41.4 \n3 Swine / pigs                      30.5 \n4 Cattle                            10.9 \n5 Cattle and Buffaloes              10.9 \n6 Goats                              8.52\n7 Sheep and Goats                    8.52\n\n\n\nafrica_1 %&gt;% \n  filter(Item %in% c(\"Major livestock types\",\"Chickens\",\"Swine / pigs\")) %&gt;% \n  ggplot(aes(x = Year,y = Livestock_Density, color = Item, group = Item)) +\n  geom_point() +\n  geom_line()\n\n\n\n\nWe now know what are the top 3 Livestock Item for Seychelles in Africa from 1960 to 2021. We will then create a time series model for each livestock Item and compare the ratio of these 3 throughout each time period.\n\n#Lets create a time series object first\nlivestock_ts_major = africa_1 %&gt;% \n  filter(Item == \"Major livestock types\") %&gt;% \n  select(Year, Livestock_Density)\n\nlivestock_ts_obj = ts(livestock_ts_major$Livestock_Density, start = 1961, frequency = 1)\n\nTransform our Time Series data to Log Form to remove fluctuations\n\nlog_ls_ts = log(livestock_ts_obj)\nplot(log_ls_ts)\n\n\n\n\nWe can see that there is an upward trend for our Time Series Data.\nFor creating the Time Series Model, we will use the function auto.arima. This will help us to identify the best configuration for our ARIMA model.\n\narima_model = auto.arima(log_ls_ts)\narima_model\n\nSeries: log_ls_ts \nARIMA(2,1,2) with drift \n\nCoefficients:\n         ar1      ar2      ma1     ma2   drift\n      0.2600  -0.7282  -0.4762  0.5582  0.0281\ns.e.  0.2804   0.1492   0.3711  0.1959  0.0130\n\nsigma^2 = 0.02032:  log likelihood = 34.13\nAIC=-56.27   AICc=-54.68   BIC=-43.7\n\n\nNow that we are done with the Model, let’s explore our ACF and PACF plots\n\nacf(arima_model$residuals, main = \"Correlogram\")\n\n\n\n\n\npacf(arima_model$residuals, main = \"Partial Correlogram\")\n\n\n\n\nTesting Significance of Residuals using Ljung-Box Test\n\nBox.test(arima_model$residuals, lag = 20, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  arima_model$residuals\nX-squared = 8.9967, df = 20, p-value = 0.9829\n\n\nSince our pvalue is greater than 0.05, we can conclude that there is no evidence that there is a Non-Zero Autocorrelation in our forecast error from Lags 1 to 20.\nNext we will generate a Residual Plot. This will help us confirm if our model is correct or if we need to consider other modelling algorithm.\n\nhist(arima_model$residuals,\n     col = \"red\",\n     xlab = \"Error\",\n     main = \"Histogram of Residuals\",\n     freq = FALSE)\n\n\n\n\nAs we can see, most of the values for Error are concentrated on 0.\nFinally, we can now start to forecast using our ARIMA model. On our script below we will try to predict the Major Livestock Density for the next 5 years\n\nmodel_forecast = forecast(arima_model, 5)\nautoplot(model_forecast)\n\n\n\n\nOur model captured the upward trend of our Log Transformed Time Series Data. The dark and light blue region indicates the confidence interval of our prediction or forecast. Notice that our model did not capture any fluctuation from our original data, that is because our data does not have a seasonality component. The up and down movement we are seeing may be due to noise but not enough for our model to consider it as a pattern for forecasting.\n\naccuracy(model_forecast)\n\n                       ME      RMSE        MAE       MPE     MAPE      MASE\nTraining set -0.000373242 0.1353569 0.09882457 -3.725761 33.46294 0.9112668\n                   ACF1\nTraining set 0.02882789\n\n\nRunning accuracy function tells us how well our model is performing. The rmse value tells us the root mean squared error of our model. Our target for this metric is for it to be lower when compared to other model performance evaluation."
  },
  {
    "objectID": "projects/diabetes_prediction/diabetes_risk_pred.html",
    "href": "projects/diabetes_prediction/diabetes_risk_pred.html",
    "title": "diabetes_risk_prediction",
    "section": "",
    "text": "Diabetes, a chronic metabolic disorder affecting millions worldwide, poses significant challenges to healthcare systems and individuals alike. Characterized by elevated blood sugar levels, diabetes arises from the body’s inability to produce or effectively utilize insulin, a hormone crucial for regulating blood sugar. Its prevalence is on the rise globally, driven by factors such as sedentary lifestyles, unhealthy dietary habits, and aging populations. Beyond its immediate health impacts, diabetes increases the risk of serious complications, including cardiovascular disease, kidney failure, and blindness, imposing substantial economic and social burdens. Addressing the complexities of diabetes requires a multifaceted approach, integrating medical interventions, lifestyle modifications, and public health initiatives. In this data science portfolio, we delve into the realm of predictive modeling to better understand diabetes risk factors, enhance early detection, and inform targeted interventions, aiming to contribute meaningfully to diabetes management and prevention efforts."
  },
  {
    "objectID": "projects/diabetes_prediction/diabetes_risk_pred.html#overview",
    "href": "projects/diabetes_prediction/diabetes_risk_pred.html#overview",
    "title": "diabetes_risk_prediction",
    "section": "",
    "text": "Diabetes, a chronic metabolic disorder affecting millions worldwide, poses significant challenges to healthcare systems and individuals alike. Characterized by elevated blood sugar levels, diabetes arises from the body’s inability to produce or effectively utilize insulin, a hormone crucial for regulating blood sugar. Its prevalence is on the rise globally, driven by factors such as sedentary lifestyles, unhealthy dietary habits, and aging populations. Beyond its immediate health impacts, diabetes increases the risk of serious complications, including cardiovascular disease, kidney failure, and blindness, imposing substantial economic and social burdens. Addressing the complexities of diabetes requires a multifaceted approach, integrating medical interventions, lifestyle modifications, and public health initiatives. In this data science portfolio, we delve into the realm of predictive modeling to better understand diabetes risk factors, enhance early detection, and inform targeted interventions, aiming to contribute meaningfully to diabetes management and prevention efforts."
  },
  {
    "objectID": "projects/diabetes_prediction/diabetes_risk_pred.html#data-dictionary",
    "href": "projects/diabetes_prediction/diabetes_risk_pred.html#data-dictionary",
    "title": "diabetes_risk_prediction",
    "section": "Data Dictionary",
    "text": "Data Dictionary\n\nAge: This represents the age of the individual in years.\nGender: This is the gender of the individual. It can be Male or Female.\nPolyuria: This refers to the presence of excessive urination, which is a common symptom of diabetes.\nPolydipsia: This refers to excessive thirst, another common symptom of diabetes.\nSudden weight loss: This indicates whether the individual has experienced unexplained weight loss, which can be a sign of diabetes.\nWeakness: This indicates whether the individual experiences general physical weakness, a potential symptom of diabetes.\nPolyphagia: This refers to excessive hunger, another potential symptom of diabetes.\nGenital thrush: This is a yeast infection that can cause itching, soreness, and other discomforts in the genital area. It can be more common in people with diabetes.\nVisual blurring: This indicates whether the individual experiences blurred vision, a potential symptom of diabetes.\nItching: This indicates whether the individual experiences general itching, which can be a symptom of diabetes.\nIrritability: This indicates whether the individual experiences irritability, which can be a symptom of diabetes.\nDelayed healing: This indicates whether the individual experiences slow healing of wounds, which can be a symptom of diabetes.\nPartial paresis: This refers to a partial loss of voluntary movement, which can be a symptom of diabetes.\nMuscle stiffness: This indicates whether the individual experiences muscle stiffness, which can be a symptom of diabetes.\nAlopecia: This refers to hair loss, which can be a symptom of diabetes.\nObesity: This indicates whether the individual is obese, which is a major risk factor for diabetes."
  },
  {
    "objectID": "projects/diabetes_prediction/diabetes_risk_pred.html#code",
    "href": "projects/diabetes_prediction/diabetes_risk_pred.html#code",
    "title": "diabetes_risk_prediction",
    "section": "Code",
    "text": "Code\n\nLibrary Import and Installation\n\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n#install.packages(\"tidymodels\")\nlibrary(tidymodels)\n#install.packages(\"data.table\")\nlibrary(data.table)"
  },
  {
    "objectID": "projects/diabetes_prediction/diabetes_risk_pred.html#data-import",
    "href": "projects/diabetes_prediction/diabetes_risk_pred.html#data-import",
    "title": "diabetes_risk_prediction",
    "section": "Data Import",
    "text": "Data Import\n\ndiabetes_data = fread(\"diabetes_risk_prediction_dataset.csv\") %&gt;% as_tibble()\n\n#Quick overview of data class\nglimpse(diabetes_data)\n\nRows: 520\nColumns: 17\n$ Age                  &lt;int&gt; 40, 58, 41, 45, 60, 55, 57, 66, 67, 70, 44, 38, 3…\n$ Gender               &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"…\n$ Polyuria             &lt;chr&gt; \"No\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n$ Polydipsia           &lt;chr&gt; \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n$ `sudden weight loss` &lt;chr&gt; \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\"…\n$ weakness             &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", …\n$ Polyphagia           &lt;chr&gt; \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"N…\n$ `Genital thrush`     &lt;chr&gt; \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\",…\n$ `visual blurring`    &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes…\n$ Itching              &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Y…\n$ Irritability         &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\",…\n$ `delayed healing`    &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"…\n$ `partial paresis`    &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes…\n$ `muscle stiffness`   &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"Ye…\n$ Alopecia             &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"N…\n$ Obesity              &lt;chr&gt; \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\"…\n$ class                &lt;chr&gt; \"Positive\", \"Positive\", \"Positive\", \"Positive\", \"…"
  },
  {
    "objectID": "projects/diabetes_prediction/diabetes_risk_pred.html#data-cleansing-and-exploratory-data-analysis",
    "href": "projects/diabetes_prediction/diabetes_risk_pred.html#data-cleansing-and-exploratory-data-analysis",
    "title": "diabetes_risk_prediction",
    "section": "Data Cleansing and Exploratory Data Analysis",
    "text": "Data Cleansing and Exploratory Data Analysis\n\n#Check Age distribution\ndiabetes_data %&gt;% \n  ggplot(aes(x = Age)) +\n  geom_histogram()\n\n\n\n#Check QQ Plot for Normality\nqqnorm(diabetes_data$Age)\nqqline(diabetes_data$Age)\n\n\n\n\nBoth QQ Plot and Histogram seems to show a normally distributed data. Let’s use shapiro.test() to perform Shapiro-Wilk test for normality.\n\nshapiro.test(diabetes_data$Age)\n\n\n    Shapiro-Wilk normality test\n\ndata:  diabetes_data$Age\nW = 0.98313, p-value = 9.992e-06\n\n\nP-value is way less than 0.05 indicating a non-normal data. Let’s take a look what will be the result if use Kolmogorov-smirnov test.\n\nks.test(diabetes_data$Age,'pnorm')\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  diabetes_data$Age\nD = 1, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\nThe age column failed both Normality Test. Age column is not normal.\nLet’s check the Gender column for frequency.\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Gender)) +\n  geom_bar()\n\n\n\n\nWe have more male than female. Let’s try to use our respondent variable as fill and see which class has the most count of Positive or Negative value for Diabetes.\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Gender, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\nThe bar graph shows how Female class have more Positive Diabetes Class compared to Male.\nLet’s check Polyuria for distribution and behavior when we add the class column as fill\n\ndiabetes_data %&gt;% \n  ggplot(aes( x = Polyuria))+\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Polyuria, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\nA clear sign of how having a Polyuria or excessive urination can be a strong indicator of Diabetes.\nLet’s check Polydipsia.\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Polydipsia)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Polydipsia, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\nAlmost the same behavior for Polydispia. Looks like Polydispia and Polyuria can be use as a strong predictor for Diabetes class.\nLet’s explore Sudden weight lost\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `sudden weight loss`)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `sudden weight loss`, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\nAnother strong indicator for Diabetes Class.\nLet’s look at Weakness column.\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = weakness)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = weakness,fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\nAnother potential indicator for positive Diabetes Class. Let’s continue to explore all of categorical variables.\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Polyphagia)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Polyphagia, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `Genital thrush`)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `Genital thrush`, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `visual blurring`)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `visual blurring`, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Itching)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Itching, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Irritability)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Irritability, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `delayed healing`)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `delayed healing`, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `partial paresis`)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `partial paresis`, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `muscle stiffness`)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = `muscle stiffness`, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Alopecia)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Alopecia, fill = class)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Obesity)) +\n  geom_bar()\n\n\n\ndiabetes_data %&gt;% \n  ggplot(aes(x = Obesity, fill = class)) +\n  geom_bar(position = \"dodge\")"
  },
  {
    "objectID": "projects/diabetes_prediction/diabetes_risk_pred.html#splitting-dataset",
    "href": "projects/diabetes_prediction/diabetes_risk_pred.html#splitting-dataset",
    "title": "diabetes_risk_prediction",
    "section": "Splitting Dataset",
    "text": "Splitting Dataset\n\ndiabetes_data_model = diabetes_data %&gt;% \n  mutate_if(is.character,as.factor)\n\nset.seed(222)\ndata_split = initial_split(diabetes_data_model, prop = 3/4)\ntraining_data = training(data_split)\ntesting_data = testing(data_split)"
  },
  {
    "objectID": "projects/diabetes_prediction/diabetes_risk_pred.html#training-data-modelling",
    "href": "projects/diabetes_prediction/diabetes_risk_pred.html#training-data-modelling",
    "title": "diabetes_risk_prediction",
    "section": "Training Data Modelling",
    "text": "Training Data Modelling\n\n#Create Recipe\ndiabetes_logit = recipe(class ~ ., data = training_data)\n\n#Prepare Model Engine\nlogit_model = logistic_reg() %&gt;% \n  set_engine(\"glm\")\n\n#Create workflow\ndiabetes_logit_workflow = workflow() %&gt;% \n  add_model(logit_model) %&gt;% \n  add_recipe(diabetes_logit)\n\n#Fit Data\ndiabetes_logit_fit = diabetes_logit_workflow %&gt;% \n  fit(data = training_data)\n\n#Extract Metrics\ndiabetes_logit_fit %&gt;% \n  extract_fit_parsnip() %&gt;% \n  tidy() %&gt;% \n  filter(p.value &lt; 0.05)\n\n# A tibble: 7 × 5\n  term                estimate std.error statistic  p.value\n  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)             2.39     1.15       2.08 3.77e- 2\n2 GenderMale             -4.50     0.704     -6.39 1.62e-10\n3 PolyuriaYes             4.45     0.799      5.57 2.57e- 8\n4 PolydipsiaYes           5.49     0.986      5.57 2.60e- 8\n5 `Genital thrush`Yes     2.12     0.660      3.22 1.30e- 3\n6 ItchingYes             -3.02     0.791     -3.82 1.35e- 4\n7 IrritabilityYes         1.94     0.687      2.82 4.87e- 3"
  },
  {
    "objectID": "projects/diabetes_prediction/diabetes_risk_pred.html#training-data-model-evaluation",
    "href": "projects/diabetes_prediction/diabetes_risk_pred.html#training-data-model-evaluation",
    "title": "diabetes_risk_prediction",
    "section": "Training Data Model Evaluation",
    "text": "Training Data Model Evaluation\nNow that we have our model, we will evaluate it first using our train data. Just for us to have an idea of how our model performs.\n\n#Predict training data using our model\npredict(diabetes_logit_fit, training_data) %&gt;% \n  count(.pred_class)\n\n# A tibble: 2 × 2\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 Negative      155\n2 Positive      235\n\n#Append our predicted class on the actual training class\ndiabetes_train_aug = augment(diabetes_logit_fit, training_data)\ndiabetes_train_aug %&gt;% \n  head()\n\n# A tibble: 6 × 20\n  .pred_class .pred_Negative .pred_Positive   Age Gender Polyuria Polydipsia\n  &lt;fct&gt;                &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     \n1 Positive        0.00000191         1.00      43 Female Yes      Yes       \n2 Positive        0.00243            0.998     67 Male   No       Yes       \n3 Negative        0.968              0.0319    43 Male   No       No        \n4 Positive        0.00000549         1.00      38 Female Yes      Yes       \n5 Positive        0.00000490         1.00      50 Female Yes      Yes       \n6 Positive        0.000103           1.00      30 Female Yes      Yes       \n# ℹ 13 more variables: `sudden weight loss` &lt;fct&gt;, weakness &lt;fct&gt;,\n#   Polyphagia &lt;fct&gt;, `Genital thrush` &lt;fct&gt;, `visual blurring` &lt;fct&gt;,\n#   Itching &lt;fct&gt;, Irritability &lt;fct&gt;, `delayed healing` &lt;fct&gt;,\n#   `partial paresis` &lt;fct&gt;, `muscle stiffness` &lt;fct&gt;, Alopecia &lt;fct&gt;,\n#   Obesity &lt;fct&gt;, class &lt;fct&gt;\n\n\nLet’s plot an ROC Curve\n\ndiabetes_train_aug %&gt;% \n  roc_curve(truth = class,.pred_Negative) %&gt;% \n  autoplot()\n\n\n\n\nThen calculate accuracy\n\ndiabetes_logit_train_pred = predict(diabetes_logit_fit, training_data) %&gt;% \n  bind_cols(predict(diabetes_logit_fit, training_data,type = \"prob\")) %&gt;% \n  bind_cols(training_data %&gt;% select(class))\n\n\ndiabetes_logit_train_pred %&gt;% \n  accuracy(truth = class, .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.918\n\n\nWe have a training accuracy of 92%. To further assess our model, let’s do 10-fold cross validation and compare it with our straight-forward training model performance."
  },
  {
    "objectID": "projects/diabetes_prediction/diabetes_risk_pred.html#cross-fold-validation",
    "href": "projects/diabetes_prediction/diabetes_risk_pred.html#cross-fold-validation",
    "title": "diabetes_risk_prediction",
    "section": "Cross-Fold Validation",
    "text": "Cross-Fold Validation\n\nset.seed(345)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Areas of Intereset",
    "section": "",
    "text": "Machine Learning\nI always enjoy developing machine learning model that helps solve a business problem.\n\n\nModel Deployment\nDeveloping a Machine Learning model is just the start. Making it usable across the company is another story. I’ve been interested on how to make\nmy machine learning models scalable and deployment ready. This includes, containerization, version control and CI/CD.\n\n\n\n\n\n\n\nData Analytics\nI love telling a story. Identifying patterns, discovering trends and interpreting it back to business is one of the main reason why I love Data Science! Making beautiful, informative and compelling presentation for me is the best part of interpreting your insight to the client.\n\n\n\n\n\n\n\nData Engineering/Developing Automated ETL/Manual Task Automation\nAutomating Task and developing ETL is one of my favorite technical skills. Having the ability to cut down the time it took for a csv file to be downloaded by using python is the best for me! Extracting, Transforming, manipulating, cleaning and loading sets of data to form a stable pipeline is a work that I will never get tired of."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RJ Dela Peña",
    "section": "",
    "text": "R Programmer. Data Scientist/Data Engineer. Unlocking Insights, Empowering Decisions"
  },
  {
    "objectID": "index.html#ray-john-dela-peña",
    "href": "index.html#ray-john-dela-peña",
    "title": "RJ Dela Peña",
    "section": "",
    "text": "R Programmer. Data Scientist/Data Engineer. Unlocking Insights, Empowering Decisions"
  },
  {
    "objectID": "projects/churn.html#about-the-data",
    "href": "projects/churn.html#about-the-data",
    "title": "Churn Analytics and Prediction",
    "section": "About the Data",
    "text": "About the Data"
  },
  {
    "objectID": "projects/churn.html#exploratory-data-analysis",
    "href": "projects/churn.html#exploratory-data-analysis",
    "title": "Churn Analytics and Prediction",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis"
  },
  {
    "objectID": "projects/hotel_predictive/pred_hotel_bookings.html",
    "href": "projects/hotel_predictive/pred_hotel_bookings.html",
    "title": "Hotel Bookings Predictive Model",
    "section": "",
    "text": "The data we are going to use is hotel bookings data. It came from Antonio, Almeida, and Nunes (2019). We will create a predictive model to predict which hotel stays included babies and/or children. We will use different hotel stay attributes to come up a prediction. Below is our data dictionary that should help us understand the data better.\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nhotel\ncharacter\nHotel (H1 = Resort Hotel or H2 = City Hotel)\n\n\nis_canceled\ndouble\nValue indicating if the booking was canceled (1) or not (0)\n\n\nlead_time\ndouble\nNumber of days that elapsed between the entering date of the booking into the PMS and the arrival date\n\n\narrival_date_year\ndouble\nYear of arrival date\n\n\narrival_date_month\ncharacter\nMonth of arrival date\n\n\narrival_date_week_number\ndouble\nWeek number of year for arrival date\n\n\narrival_date_day_of_month\ndouble\nDay of arrival date\n\n\nstays_in_weekend_nights\ndouble\nNumber of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n\n\nstays_in_week_nights\ndouble\nNumber of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n\n\nadults\ndouble\nNumber of adults\n\n\nchildren\ndouble\nNumber of children\n\n\nbabies\ndouble\nNumber of babies\n\n\nmeal\ncharacter\nType of meal booked. Categories are presented in standard hospitality meal packages:\nUndefined/SC – no meal package;\nBB – Bed & Breakfast;\nHB – Half board (breakfast and one other meal – usually dinner);\nFB – Full board (breakfast, lunch and dinner)\n\n\ncountry\ncharacter\nCountry of origin. Categories are represented in the ISO 3155–3:2013 format\n\n\nmarket_segment\ncharacter\nMarket segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\ndistribution_channel\ncharacter\nBooking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\nis_repeated_guest\ndouble\nValue indicating if the booking name was from a repeated guest (1) or not (0)\n\n\nprevious_cancellations\ndouble\nNumber of previous bookings that were cancelled by the customer prior to the current booking\n\n\nprevious_bookings_not_canceled\ndouble\nNumber of previous bookings not cancelled by the customer prior to the current booking\n\n\nreserved_room_type\ncharacter\nCode of room type reserved. Code is presented instead of designation for anonymity reasons\n\n\nassigned_room_type\ncharacter\nCode for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons\n\n\nbooking_changes\ndouble\nNumber of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n\n\ndeposit_type\ncharacter\nIndication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:\nNo Deposit – no deposit was made;\nNon Refund – a deposit was made in the value of the total stay cost;\nRefundable – a deposit was made with a value under the total cost of stay.\n\n\nagent\ncharacter\nID of the travel agency that made the booking\n\n\ncompany\ncharacter\nID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons\n\n\ndays_in_waiting_list\ndouble\nNumber of days the booking was in the waiting list before it was confirmed to the customer\n\n\ncustomer_type\ncharacter\nType of booking, assuming one of four categories:\nContract - when the booking has an allotment or other type of contract associated to it;\nGroup – when the booking is associated to a group;\nTransient – when the booking is not part of a group or contract, and is not associated to other transient booking;\nTransient-party – when the booking is transient, but is associated to at least other transient booking\n\n\nadr\ndouble\nAverage Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights\n\n\nrequired_car_parking_spaces\ndouble\nNumber of car parking spaces required by the customer\n\n\ntotal_of_special_requests\ndouble\nNumber of special requests made by the customer (e.g. twin bed or high floor)\n\n\nreservation_status\ncharacter\nReservation last status, assuming one of three categories:\nCanceled – booking was canceled by the customer;\nCheck-Out – customer has checked in but already departed;\nNo-Show – customer did not check-in and did inform the hotel of the reason why\n\n\nreservation_status_date\ndouble\nDate at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel"
  },
  {
    "objectID": "projects/hotel_predictive/pred_hotel_bookings.html#overview",
    "href": "projects/hotel_predictive/pred_hotel_bookings.html#overview",
    "title": "Hotel Bookings Predictive Model",
    "section": "",
    "text": "The data we are going to use is hotel bookings data. It came from Antonio, Almeida, and Nunes (2019). We will create a predictive model to predict which hotel stays included babies and/or children. We will use different hotel stay attributes to come up a prediction. Below is our data dictionary that should help us understand the data better.\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nhotel\ncharacter\nHotel (H1 = Resort Hotel or H2 = City Hotel)\n\n\nis_canceled\ndouble\nValue indicating if the booking was canceled (1) or not (0)\n\n\nlead_time\ndouble\nNumber of days that elapsed between the entering date of the booking into the PMS and the arrival date\n\n\narrival_date_year\ndouble\nYear of arrival date\n\n\narrival_date_month\ncharacter\nMonth of arrival date\n\n\narrival_date_week_number\ndouble\nWeek number of year for arrival date\n\n\narrival_date_day_of_month\ndouble\nDay of arrival date\n\n\nstays_in_weekend_nights\ndouble\nNumber of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n\n\nstays_in_week_nights\ndouble\nNumber of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n\n\nadults\ndouble\nNumber of adults\n\n\nchildren\ndouble\nNumber of children\n\n\nbabies\ndouble\nNumber of babies\n\n\nmeal\ncharacter\nType of meal booked. Categories are presented in standard hospitality meal packages:\nUndefined/SC – no meal package;\nBB – Bed & Breakfast;\nHB – Half board (breakfast and one other meal – usually dinner);\nFB – Full board (breakfast, lunch and dinner)\n\n\ncountry\ncharacter\nCountry of origin. Categories are represented in the ISO 3155–3:2013 format\n\n\nmarket_segment\ncharacter\nMarket segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\ndistribution_channel\ncharacter\nBooking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\nis_repeated_guest\ndouble\nValue indicating if the booking name was from a repeated guest (1) or not (0)\n\n\nprevious_cancellations\ndouble\nNumber of previous bookings that were cancelled by the customer prior to the current booking\n\n\nprevious_bookings_not_canceled\ndouble\nNumber of previous bookings not cancelled by the customer prior to the current booking\n\n\nreserved_room_type\ncharacter\nCode of room type reserved. Code is presented instead of designation for anonymity reasons\n\n\nassigned_room_type\ncharacter\nCode for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons\n\n\nbooking_changes\ndouble\nNumber of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n\n\ndeposit_type\ncharacter\nIndication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:\nNo Deposit – no deposit was made;\nNon Refund – a deposit was made in the value of the total stay cost;\nRefundable – a deposit was made with a value under the total cost of stay.\n\n\nagent\ncharacter\nID of the travel agency that made the booking\n\n\ncompany\ncharacter\nID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons\n\n\ndays_in_waiting_list\ndouble\nNumber of days the booking was in the waiting list before it was confirmed to the customer\n\n\ncustomer_type\ncharacter\nType of booking, assuming one of four categories:\nContract - when the booking has an allotment or other type of contract associated to it;\nGroup – when the booking is associated to a group;\nTransient – when the booking is not part of a group or contract, and is not associated to other transient booking;\nTransient-party – when the booking is transient, but is associated to at least other transient booking\n\n\nadr\ndouble\nAverage Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights\n\n\nrequired_car_parking_spaces\ndouble\nNumber of car parking spaces required by the customer\n\n\ntotal_of_special_requests\ndouble\nNumber of special requests made by the customer (e.g. twin bed or high floor)\n\n\nreservation_status\ncharacter\nReservation last status, assuming one of three categories:\nCanceled – booking was canceled by the customer;\nCheck-Out – customer has checked in but already departed;\nNo-Show – customer did not check-in and did inform the hotel of the reason why\n\n\nreservation_status_date\ndouble\nDate at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel"
  },
  {
    "objectID": "projects/hotel_predictive/pred_hotel_bookings.html#library-and-data-import",
    "href": "projects/hotel_predictive/pred_hotel_bookings.html#library-and-data-import",
    "title": "Hotel Bookings Predictive Model",
    "section": "Library and Data Import",
    "text": "Library and Data Import\n\nlibrary(tidymodels)\nlibrary(readr)\nlibrary(vip)\n\nhotels = read_csv(\"https://tidymodels.org/start/case-study/hotels.csv\") %&gt;%\n  mutate(across(where(is.character), as.factor))"
  },
  {
    "objectID": "projects/hotel_predictive/pred_hotel_bookings.html#outcome-variable-checking",
    "href": "projects/hotel_predictive/pred_hotel_bookings.html#outcome-variable-checking",
    "title": "Hotel Bookings Predictive Model",
    "section": "Outcome Variable Checking",
    "text": "Outcome Variable Checking\nOur goal is to build a motel that will predict which hotel stays included a children and/or babies and which did not. The column that will serve us our outcome variable is children.\n\nhotels %&gt;% \n  count(children) %&gt;% \n  mutate(\n    prop = paste( round((n/sum(n)) * 100,2),\"%\",sep = \"\")\n  )\n\n# A tibble: 2 × 3\n  children     n prop  \n  &lt;fct&gt;    &lt;int&gt; &lt;chr&gt; \n1 children  4038 8.08% \n2 none     45962 91.92%\n\n\nWe have here the proportion of hotel stay with and without children in it."
  },
  {
    "objectID": "projects/hotel_predictive/pred_hotel_bookings.html#data-splitting-and-resampling",
    "href": "projects/hotel_predictive/pred_hotel_bookings.html#data-splitting-and-resampling",
    "title": "Hotel Bookings Predictive Model",
    "section": "Data Splitting and Resampling",
    "text": "Data Splitting and Resampling\nWe will use 70/30 split for our train and test data. Since we have an imbalance outcome variable class, we will use a stratified sample.\n\nset.seed(123)\nsplits = initial_split(hotels, strata = children)\n\nhotel_train = training(splits)\nhotel_test = testing(splits)\n\n\n#Check Training set children proportion\nhotel_train %&gt;% \n  count(children) %&gt;% \n  mutate(\n    prop = n/sum(n)\n  )\n\n# A tibble: 2 × 3\n  children     n   prop\n  &lt;fct&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 children  3027 0.0807\n2 none     34473 0.919 \n\n#Check Testing Set children proportion\nhotel_test %&gt;% \n  count(children) %&gt;% \n  mutate(prop = n/sum(n))\n\n# A tibble: 2 × 3\n  children     n   prop\n  &lt;fct&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 children  1011 0.0809\n2 none     11489 0.919 \n\n\nWe will use validation set resmpling method for our data splits.\n\nset.seed(234)\n\nval_set = validation_split(hotel_train,\n                           strata = children,\n                           prop = 0.80)\n\nval_set\n\n# Validation Set Split (0.8/0.2)  using stratification \n# A tibble: 1 × 2\n  splits               id        \n  &lt;list&gt;               &lt;chr&gt;     \n1 &lt;split [30000/7500]&gt; validation"
  },
  {
    "objectID": "projects/hotel_predictive/pred_hotel_bookings.html#model-1-penalized-logistic-regression",
    "href": "projects/hotel_predictive/pred_hotel_bookings.html#model-1-penalized-logistic-regression",
    "title": "Hotel Bookings Predictive Model",
    "section": "Model #1: Penalized Logistic Regression",
    "text": "Model #1: Penalized Logistic Regression\nOur outcome variable is a categorical column so its only reasonable for us to select Logistic Regression as our base model.\n\nlr_mod = logistic_reg(penalty = tune(), mixture = 1) %&gt;% \n  set_engine(\"glmnet\")\n\nWe set the penalty argument to tune() for now to serve as a placeholder temporarily. mixture was set to 1 to instruct our model to remove any possible nuisance variable keeping our model simple.\nWe can now proceed on creating our model recipe.\n\nholidays &lt;- c(\"AllSouls\", \"AshWednesday\", \"ChristmasEve\", \"Easter\", \n              \"ChristmasDay\", \"GoodFriday\", \"NewYearsDay\", \"PalmSunday\")\n\nlr_recipe = recipe(children ~ ., data = hotel_train) %&gt;% \n  step_date(arrival_date) %&gt;% \n  step_holiday(arrival_date, holidays = holidays) %&gt;% \n  step_rm(arrival_date) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_zv(all_predictors()) %&gt;% \n  step_normalize(all_predictors())\n\nCreating Workflow\n\nlr_workflow = workflow() %&gt;% \n  add_model(lr_mod) %&gt;% \n  add_recipe(lr_recipe) \n\nNext, grid tuning object.\n\nlr_reg_grid &lt;- tibble(penalty = 10^seq(-4, -1, length.out = 30))\n\nlr_reg_grid %&gt;% top_n(-5) # lowest penalty values\n\n# A tibble: 5 × 1\n   penalty\n     &lt;dbl&gt;\n1 0.0001  \n2 0.000127\n3 0.000161\n4 0.000204\n5 0.000259\n\nlr_reg_grid %&gt;% top_n(5)  # highest penalty values\n\n# A tibble: 5 × 1\n  penalty\n    &lt;dbl&gt;\n1  0.0386\n2  0.0489\n3  0.0621\n4  0.0788\n5  0.1   \n\n\n\nModel Training and Tuning\n\nlr_res &lt;- \n  lr_workflow %&gt;% \n  tune_grid(val_set,\n            grid = lr_reg_grid,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(roc_auc))\n\n\nlr_plot &lt;- \n  lr_res %&gt;% \n  collect_metrics() %&gt;% \n  ggplot(aes(x = penalty, y = mean)) + \n  geom_point() + \n  geom_line() + \n  ylab(\"Area under the ROC Curve\") +\n  scale_x_log10(labels = scales::label_number())\n\nlr_plot \n\n\n\n\nThis plots shows us that model performance is generally better at the smaller penalty values. This suggests that the majority of the predictors are important to the model. We also see a steep drop in the area under the ROC curve towards the highest penalty values. This happens because a large enough penalty will remove all predictors from the model, and not surprisingly predictive accuracy plummets with no predictors in the model (recall that an ROC AUC value of 0.50 means that the model does no better than chance at predicting the correct class).\n\ntop_models &lt;-\n  lr_res %&gt;% \n  show_best(\"roc_auc\", n = 15) %&gt;% \n  arrange(penalty) \ntop_models\n\n# A tibble: 15 × 7\n    penalty .metric .estimator  mean     n std_err .config              \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1 0.000127 roc_auc binary     0.872     1      NA Preprocessor1_Model02\n 2 0.000161 roc_auc binary     0.872     1      NA Preprocessor1_Model03\n 3 0.000204 roc_auc binary     0.873     1      NA Preprocessor1_Model04\n 4 0.000259 roc_auc binary     0.873     1      NA Preprocessor1_Model05\n 5 0.000329 roc_auc binary     0.874     1      NA Preprocessor1_Model06\n 6 0.000418 roc_auc binary     0.874     1      NA Preprocessor1_Model07\n 7 0.000530 roc_auc binary     0.875     1      NA Preprocessor1_Model08\n 8 0.000672 roc_auc binary     0.875     1      NA Preprocessor1_Model09\n 9 0.000853 roc_auc binary     0.876     1      NA Preprocessor1_Model10\n10 0.00108  roc_auc binary     0.876     1      NA Preprocessor1_Model11\n11 0.00137  roc_auc binary     0.876     1      NA Preprocessor1_Model12\n12 0.00174  roc_auc binary     0.876     1      NA Preprocessor1_Model13\n13 0.00221  roc_auc binary     0.876     1      NA Preprocessor1_Model14\n14 0.00281  roc_auc binary     0.875     1      NA Preprocessor1_Model15\n15 0.00356  roc_auc binary     0.873     1      NA Preprocessor1_Model16\n\n\n\nlr_best &lt;- \n  lr_res %&gt;% \n  collect_metrics() %&gt;% \n  arrange(penalty) %&gt;% \n  slice(12)\nlr_best\n\n# A tibble: 1 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1 0.00137 roc_auc binary     0.876     1      NA Preprocessor1_Model12\n\n#&gt; # A tibble: 1 × 7\n#&gt;   penalty .metric .estimator  mean     n std_err .config              \n#&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n#&gt; 1 0.00137 roc_auc binary     0.876     1      NA Preprocessor1_Model12\n\n\nlr_auc &lt;- \n  lr_res %&gt;% \n  collect_predictions(parameters = lr_best) %&gt;% \n  roc_curve(children, .pred_children) %&gt;% \n  mutate(model = \"Logistic Regression\")\n\nautoplot(lr_auc)"
  },
  {
    "objectID": "projects/hotel_predictive/pred_hotel_bookings.html#second-model-tree-based-ensemble-or-random-forest",
    "href": "projects/hotel_predictive/pred_hotel_bookings.html#second-model-tree-based-ensemble-or-random-forest",
    "title": "Hotel Bookings Predictive Model",
    "section": "Second Model: Tree-Based Ensemble or Random Forest",
    "text": "Second Model: Tree-Based Ensemble or Random Forest\nRandom forest is an efficient yet low-maintenance machine learning model. It offers more flexibility in data types and result compared to Logistic Regression. It is a type of ensemble model mostly containing thousands of decision trees, where each Decision Tree iteration used a slightly different version of the training data and learns a sequence of splitting rules to predict new data. We are going to utilize all of our available cores to improve the training time of our model\n\ncores = parallel::detectCores()\ncores\n\n[1] 16\n\n\nWe have 16 available cores to work with. We can pass it on our model for parallel processing.\n\nrf_mod = rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %&gt;% \n  set_engine(\"ranger\",num.threads = cores) %&gt;% \n  set_mode(\"classification\")\n\n#Create the recipe and workflow\n\nrf_recipe &lt;- \n  recipe(children ~ ., data = hotel_train) %&gt;% \n  step_date(arrival_date) %&gt;% \n  step_holiday(arrival_date) %&gt;% \n  step_rm(arrival_date) \n\nThen we are going to add this recipe to our parsnip model for a new workflow on predicting whether a children is included on a hotel stay.\n\nrf_workflow = workflow() %&gt;% \n  add_model(rf_mod) %&gt;% \n  add_recipe(rf_recipe)\n\nTrain and Tune the model.\n\nrf_mod\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nEngine-Specific Arguments:\n  num.threads = cores\n\nComputational engine: ranger \n\n#&gt; Random Forest Model Specification (classification)\n#&gt; \n#&gt; Main Arguments:\n#&gt;   mtry = tune()\n#&gt;   trees = 1000\n#&gt;   min_n = tune()\n#&gt; \n#&gt; Engine-Specific Arguments:\n#&gt;   num.threads = cores\n#&gt; \n#&gt; Computational engine: ranger\n\n# show what will be tuned\nextract_parameter_set_dials(rf_mod)\n\nCollection of 2 parameters for tuning\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      min_n min_n nparam[+]\n\nModel parameters needing finalization:\n   # Randomly Selected Predictors ('mtry')\n\nSee `?dials::finalize` or `?dials::update.parameters` for more information.\n\n#&gt; Collection of 2 parameters for tuning\n#&gt; \n#&gt;  identifier  type    object\n#&gt;        mtry  mtry nparam[?]\n#&gt;       min_n min_n nparam[+]\n#&gt; \n#&gt; Model parameters needing finalization:\n#&gt;    # Randomly Selected Predictors ('mtry')\n#&gt; \n#&gt; See `?dials::finalize` or `?dials::update.parameters` for more information.\n\n\nset.seed(345)\nrf_res &lt;- \n  rf_workflow %&gt;% \n  tune_grid(val_set,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(roc_auc))\n#&gt; i Creating pre-processing data to finalize unknown parameter: mtry\n\nLet’s check the top 5 random forest model out of the 25 candidates.\n\nrf_res %&gt;% \n  show_best(metric = \"roc_auc\")\n\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1     8     7 roc_auc binary     0.926     1      NA Preprocessor1_Model13\n2    12     7 roc_auc binary     0.925     1      NA Preprocessor1_Model01\n3     9    12 roc_auc binary     0.925     1      NA Preprocessor1_Model19\n4     7    25 roc_auc binary     0.924     1      NA Preprocessor1_Model03\n5    13     4 roc_auc binary     0.924     1      NA Preprocessor1_Model05\n\n\nWe can already see how the result of random forest is way better compared to the penalized logistic regression which resulted to an ROC AUC of 0.876. Let’s continue by selecting the best model.\n\nrf_best &lt;- \n  rf_res %&gt;% \n  select_best(metric = \"roc_auc\")\nrf_best\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     8     7 Preprocessor1_Model13\n\n#&gt; # A tibble: 1 × 3\n#&gt;    mtry min_n .config              \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n#&gt; 1     8     7 Preprocessor1_Model13\n\nWe will collect the data we need to plot an ROC AUC curve and compare it with the penalized Logistic Regression ROC AUC Curve\n\nrf_res %&gt;% \n  collect_predictions()\n\n# A tibble: 187,500 × 8\n   id         .pred_children .pred_none  .row  mtry min_n children .config      \n   &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt;    &lt;chr&gt;        \n 1 validation       0.148         0.852    13    12     7 none     Preprocessor…\n 2 validation       0.0262        0.974    20    12     7 none     Preprocessor…\n 3 validation       0.472         0.528    22    12     7 children Preprocessor…\n 4 validation       0.00918       0.991    23    12     7 none     Preprocessor…\n 5 validation       0.0110        0.989    31    12     7 none     Preprocessor…\n 6 validation       0.000643      0.999    38    12     7 none     Preprocessor…\n 7 validation       0             1        39    12     7 none     Preprocessor…\n 8 validation       0.00235       0.998    50    12     7 none     Preprocessor…\n 9 validation       0.0217        0.978    54    12     7 none     Preprocessor…\n10 validation       0.0389        0.961    57    12     7 children Preprocessor…\n# ℹ 187,490 more rows\n\nrf_auc &lt;- \n  rf_res %&gt;% \n  collect_predictions(parameters = rf_best) %&gt;% \n  roc_curve(children, .pred_children) %&gt;% \n  mutate(model = \"Random Forest\")\n\n\nbind_rows(rf_auc, lr_auc) %&gt;% \n  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + \n  geom_path(lwd = 1.5, alpha = 0.8) +\n  geom_abline(lty = 3) + \n  coord_equal() + \n  scale_color_viridis_d(option = \"plasma\", end = .6)"
  },
  {
    "objectID": "projects/hotel_predictive/pred_hotel_bookings.html#the-final-model",
    "href": "projects/hotel_predictive/pred_hotel_bookings.html#the-final-model",
    "title": "Hotel Bookings Predictive Model",
    "section": "The Final Model",
    "text": "The Final Model\nWe will now finalize the model with its best performing hyperparameter values.\n\n# the last model\nlast_rf_mod &lt;- \n  rand_forest(mtry = 8, min_n = 7, trees = 1000) %&gt;% \n  set_engine(\"ranger\", num.threads = cores, importance = \"impurity\") %&gt;% \n  set_mode(\"classification\")\n\n# the last workflow\nlast_rf_workflow &lt;- \n  rf_workflow %&gt;% \n  update_model(last_rf_mod)\n\n# the last fit\nset.seed(345)\nlast_rf_fit &lt;- \n  last_rf_workflow %&gt;% \n  last_fit(splits)\n\nlast_rf_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                id             .metrics .notes   .predictions .workflow \n  &lt;list&gt;                &lt;chr&gt;          &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [37500/12500]&gt; train/test sp… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\nEvaluating Final Model performance\n\nlast_rf_fit %&gt;% \n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.946 Preprocessor1_Model1\n2 roc_auc  binary         0.924 Preprocessor1_Model1\n\n\nCheck variable importance\n\nlast_rf_fit %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip(num_features = 20)\n\n\n\n\nPlotting the ROC Curve of the Final Model\n\nlast_rf_fit %&gt;% \n  collect_predictions() %&gt;% \n  roc_curve(children, .pred_children) %&gt;% \n  autoplot()"
  },
  {
    "objectID": "projects/telecom_churn/churn_telecom.html",
    "href": "projects/telecom_churn/churn_telecom.html",
    "title": "Telecom Customer Churn Analysis",
    "section": "",
    "text": "Churn is the percentage of customers that stop using a service or product over a given period of time. It is an important metric that most of the company is tracking. Analyzing churn will help the organization to identify how huge their churn rate is, what is causing the churn and how can they prevent it from happening.\nOn this project, we will use Telecom Customer Churn data to answer the following questions:\n\nWhat is the proportion of Customer that Churned to those who did not?\nWhich State has the highest churn rate?\nWhat attribute is contributing on the probability that a customer will churn?\n\nAfter answering Exploratory Questions we will proceed to create 3 Classification Model that will predict Churn. We will compare each model and decide which model to use for predicting whether a customer will churn or no."
  },
  {
    "objectID": "projects/telecom_churn/churn_telecom.html#overview",
    "href": "projects/telecom_churn/churn_telecom.html#overview",
    "title": "Telecom Customer Churn Analysis",
    "section": "",
    "text": "Churn is the percentage of customers that stop using a service or product over a given period of time. It is an important metric that most of the company is tracking. Analyzing churn will help the organization to identify how huge their churn rate is, what is causing the churn and how can they prevent it from happening.\nOn this project, we will use Telecom Customer Churn data to answer the following questions:\n\nWhat is the proportion of Customer that Churned to those who did not?\nWhich State has the highest churn rate?\nWhat attribute is contributing on the probability that a customer will churn?\n\nAfter answering Exploratory Questions we will proceed to create 3 Classification Model that will predict Churn. We will compare each model and decide which model to use for predicting whether a customer will churn or no."
  },
  {
    "objectID": "projects/telecom_churn/churn_telecom.html#library-and-data-import",
    "href": "projects/telecom_churn/churn_telecom.html#library-and-data-import",
    "title": "Telecom Customer Churn Analysis",
    "section": "Library and Data Import",
    "text": "Library and Data Import\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(data.table)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(doParallel)\n\nall_cores = parallel::detectCores(logical = FALSE)\ndoParallel::registerDoParallel(cores = all_cores)\n\nchurn_data = fread(\"churn_data.csv\") %&gt;% as_tibble()"
  },
  {
    "objectID": "projects/telecom_churn/churn_telecom.html#exploratory-data-analysis",
    "href": "projects/telecom_churn/churn_telecom.html#exploratory-data-analysis",
    "title": "Telecom Customer Churn Analysis",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nCheck Cardinality\n\n#Check State column \nchurn_data %&gt;% \n  count(State, sort = TRUE)\n\n# A tibble: 51 × 2\n   State     n\n   &lt;chr&gt; &lt;int&gt;\n 1 WV      106\n 2 MN       84\n 3 NY       83\n 4 AL       80\n 5 OH       78\n 6 OR       78\n 7 WI       78\n 8 VA       77\n 9 WY       77\n10 CT       74\n# ℹ 41 more rows\n\n\n\n#Check International Plan and Voice Mail Plan\nchurn_data %&gt;% \n  count(`International plan`,sort = TRUE)\n\n# A tibble: 2 × 2\n  `International plan`     n\n  &lt;chr&gt;                &lt;int&gt;\n1 No                    3010\n2 Yes                    323\n\nchurn_data %&gt;% \n  count(`Voice mail plan`,sort = TRUE)\n\n# A tibble: 2 × 2\n  `Voice mail plan`     n\n  &lt;chr&gt;             &lt;int&gt;\n1 No                 2411\n2 Yes                 922\n\n\nMajority of customers don’t have an International and Voice Mail plan\n\nchurn_data %&gt;% \n  filter(`Number vmail messages` != 0) %&gt;% \n  ggplot(aes(x = `Number vmail messages`)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFor the number of vmail messages among those customers that has a Voice mail plan, we can see that most of the count are concentrated on 30 voice mail messages. I filtered out those customers with no voice mail plan to avoid underestimation of our histogram for the customers that has the voice mail plan.\nThe next numerical columns we will explore are all measure of how many minutes that customer spent for calling during the day, eve, night and international call if the customer has an international call plan.\nLet’s visualize the distribution for day usage.\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total day minutes`)) +\n  geom_histogram()\n\n\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total day calls`)) +\n  geom_histogram()\n\n\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total day charge`)) +\n  geom_histogram()\n\n\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total day minutes`,y = `Total day charge`)) +\n  geom_point()\n\n\n\n\nAlmost perfect linear relationship between charge and minutes. This is expected to happen as we will be charge more the longer we use the phone for calls.\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total day calls`, y = `Total day minutes`)) +\n  geom_point()\n\n\n\n\nTotal Day Calls column seems to have a different relationship with minutes. This kind of make sense, because the number of calls you make per day doesn’t really mean that you will have higher minutes of call. One can make 3 calls in day where in each call lasts for 30 minutes, while another person can make 10 phone calls with each call lasting for only 1 minute.\nLet’s try to associate our target variable to see what is the difference of Total Day distribution for Customers that Churned and for those who did not.\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total day calls`,fill = Churn)) +\n  geom_histogram()\n\n\n\n\nAs expected, customers that are not using the service for phone calls will tend to just end their subscription. Let’s see if this will be the same pattern for minutes and charge.\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total day charge`, fill = Churn)) +\n  geom_histogram()\n\n\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total day minutes`, fill = Churn)) +\n  geom_histogram()\n\n\n\n\nAs expected, minutes and charge exhibits the same behavior for Customers that Churned and did not. Next, let’s take a look on eve charge, minutes and calls.\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total eve calls`))+\n  geom_histogram()\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total eve calls`, fill = Churn))+\n  geom_histogram()\n\n\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total eve charge`))+\n  geom_histogram()\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total eve charge`, fill = Churn))+\n  geom_histogram()\n\n\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total eve minutes`))+\n  geom_histogram()\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total eve minutes`, fill = Churn))+\n  geom_histogram()\n\n\n\n\nAs we can see from the visuals above, the distribution with and without filter follows the same pattern from the day calls, minutes and charge. Lets continue to explore the distribution for night and international minutes, calls and charge\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total night calls`, fill = Churn))+\n  geom_histogram()\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total night minutes`, fill = Churn))+\n  geom_histogram()\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total night charge`, fill = Churn))+\n  geom_histogram()\n\n\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total intl calls`, fill = Churn)) +\n  geom_histogram()\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total intl minutes`, fill = Churn)) +\n  geom_histogram()\n\n\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Total intl charge`, fill = Churn)) +\n  geom_histogram()\n\n\n\n\nTotal International calls is different from the rest of distribution since it is skewed. Finally, let’s check our service calls column.\n\nchurn_data %&gt;% \n  ggplot(aes(x = `Customer service calls`, fill = Churn)) +\n  geom_histogram()"
  },
  {
    "objectID": "projects/telecom_churn/churn_telecom.html#data-split",
    "href": "projects/telecom_churn/churn_telecom.html#data-split",
    "title": "Telecom Customer Churn Analysis",
    "section": "Data Split",
    "text": "Data Split\nNow that we have some assumptions from the EDA we did, we can start preparing our data by splitting it into test and train data set. This is a vital part of any machine learning model project. This will allow our model to learn the pattern of our data and use that to predict unseen data coming from our test data set.\n\nset.seed(222)\n\n#Lets Remove Account Length and Area code from our data set\nchurn_data_model = churn_data %&gt;% \n  select(-c(`Account length`,`Area code`)) %&gt;% \n  mutate(\n    Churn = ifelse(Churn,1,0) %&gt;% as.factor()\n  )\n\ndata_split = initial_split(churn_data_model, prop = 3/4)\ntrain_data = training(data_split)\ntest_data = testing(data_split)\n\nThat’s it! We now have 2 sets of data for our modelling. Now we need to create a recipe for basic logistic regression."
  },
  {
    "objectID": "projects/telecom_churn/churn_telecom.html#data-modelling",
    "href": "projects/telecom_churn/churn_telecom.html#data-modelling",
    "title": "Telecom Customer Churn Analysis",
    "section": "Data Modelling",
    "text": "Data Modelling\nFor tidymodels ecosystem, the first step in data modelling is creating your model recipe. Here in our case, we will predict Churn based on all available variables using our train data. Then we will initialize our model engine which GLM since we will use Logistic Regression for our base model. Once we are done with our recipe and engine model, we will add those 2 on our workflow to prepare it for the actual model fitting.\n\n#Create Recipe\nchurn_recipe = recipe(Churn ~ ., data = train_data)\n\nlogit_model = logistic_reg() %&gt;% \n  set_engine(\"glm\")\n\nchurn_workflow = workflow() %&gt;% \n  add_model(logit_model) %&gt;% \n  add_recipe(churn_recipe)\n\nchurn_fit = churn_workflow %&gt;% \n  fit(data = train_data)\n\nWe can check the result of our base model by using the function extract_fit_parsnip and tidy.\n\nchurn_fit %&gt;% \n  extract_fit_parsnip() %&gt;% \n  tidy() %&gt;% \n  filter(p.value &lt; 0.05)\n\n# A tibble: 9 × 5\n  term                     estimate std.error statistic  p.value\n  &lt;chr&gt;                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)               -9.76      1.06       -9.24 2.53e-20\n2 StateCA                    1.78      0.830       2.14 3.21e- 2\n3 StateME                    1.57      0.758       2.08 3.79e- 2\n4 StateMT                    1.79      0.743       2.41 1.60e- 2\n5 StateNJ                    1.50      0.730       2.05 4.04e- 2\n6 `International plan`Yes    2.23      0.176      12.7  6.56e-37\n7 `Voice mail plan`Yes      -1.92      0.708      -2.71 6.81e- 3\n8 `Total intl calls`        -0.0841    0.0299     -2.82 4.84e- 3\n9 `Customer service calls`   0.502     0.0473     10.6  2.29e-26"
  },
  {
    "objectID": "projects/telecom_churn/churn_telecom.html#data-prediction-and-evaluation",
    "href": "projects/telecom_churn/churn_telecom.html#data-prediction-and-evaluation",
    "title": "Telecom Customer Churn Analysis",
    "section": "Data Prediction and Evaluation",
    "text": "Data Prediction and Evaluation\nNow that we have our model trained, we can proceed on predicting unseen data using our test data set.\n\npredict(churn_fit, test_data) %&gt;% \n  count(.pred_class)\n\n# A tibble: 2 × 2\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0             788\n2 1              46\n\n\nOur Model predicted 788 customers that did not churn and 46 that did churn. We can view it another format where we can check the predicted class probabilities for the Churn column.\n\nchurn_aug = augment(churn_fit,test_data)\n\nchurn_aug %&gt;% \n  head()\n\n# A tibble: 6 × 21\n  .pred_class .pred_0 .pred_1 State `International plan` `Voice mail plan`\n  &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                &lt;chr&gt;            \n1 0             0.978  0.0217 HI    No                   No               \n2 0             0.763  0.237  ID    No                   No               \n3 0             0.962  0.0383 KY    No                   No               \n4 0             0.941  0.0594 LA    No                   No               \n5 0             0.918  0.0825 NM    No                   No               \n6 0             0.915  0.0855 IN    No                   No               \n# ℹ 15 more variables: `Number vmail messages` &lt;int&gt;,\n#   `Total day minutes` &lt;dbl&gt;, `Total day calls` &lt;int&gt;,\n#   `Total day charge` &lt;dbl&gt;, `Total eve minutes` &lt;dbl&gt;,\n#   `Total eve calls` &lt;int&gt;, `Total eve charge` &lt;dbl&gt;,\n#   `Total night minutes` &lt;dbl&gt;, `Total night calls` &lt;int&gt;,\n#   `Total night charge` &lt;dbl&gt;, `Total intl minutes` &lt;dbl&gt;,\n#   `Total intl calls` &lt;int&gt;, `Total intl charge` &lt;dbl&gt;, …\n\n\nTo start our model evaluation, Let’s generate an ROC curve.\n\nchurn_aug %&gt;% \n  roc_curve(truth = Churn,.pred_0) %&gt;% \n  autoplot()\n\n\n\n\nCalculate Accuracy of our model\n\nchurn_testing_pred = predict(churn_fit, test_data) %&gt;% \n  bind_cols(predict(churn_fit, test_data, type = \"prob\")) %&gt;% \n  bind_cols(test_data %&gt;% select(Churn))\n\nchurn_testing_pred\n\n# A tibble: 834 × 4\n   .pred_class .pred_0 .pred_1 Churn\n   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;\n 1 0             0.978  0.0217 0    \n 2 0             0.763  0.237  1    \n 3 0             0.962  0.0383 0    \n 4 0             0.941  0.0594 0    \n 5 0             0.918  0.0825 0    \n 6 0             0.915  0.0855 0    \n 7 0             0.969  0.0315 0    \n 8 0             0.774  0.226  0    \n 9 0             0.950  0.0498 0    \n10 0             0.904  0.0957 0    \n# ℹ 824 more rows\n\n\n\nchurn_testing_pred %&gt;% \n  accuracy(truth = Churn, .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.865\n\n\nNot bad! We got an accuracy rate of 86% for base model without even doing extensive data pre-processing. But what we did from the script above is a basic data split and modelling. Now let’s try enhancing our data split process by doing a K-Fold Cross Validation and see if it will help our model to perform better.\n\nset.seed(345)\n\nfolds = vfold_cv(train_data, v = 10)\nfolds\n\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits             id    \n   &lt;list&gt;             &lt;chr&gt; \n 1 &lt;split [2249/250]&gt; Fold01\n 2 &lt;split [2249/250]&gt; Fold02\n 3 &lt;split [2249/250]&gt; Fold03\n 4 &lt;split [2249/250]&gt; Fold04\n 5 &lt;split [2249/250]&gt; Fold05\n 6 &lt;split [2249/250]&gt; Fold06\n 7 &lt;split [2249/250]&gt; Fold07\n 8 &lt;split [2249/250]&gt; Fold08\n 9 &lt;split [2249/250]&gt; Fold09\n10 &lt;split [2250/249]&gt; Fold10\n\n\nLets create a new workflow for this approach\n\nchurn_Cv_wf = workflow() %&gt;% \n  add_model(logit_model) %&gt;% \n  add_formula(Churn ~ .) \n\nset.seed(456)\n\nchurn_cv_fit = churn_Cv_wf %&gt;% \n  fit_resamples(folds)\n\ncollect_metrics(churn_cv_fit)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.858    10 0.00900 Preprocessor1_Model1\n2 roc_auc  binary     0.796    10 0.0121  Preprocessor1_Model1\n\n\nThe result above shows that the performance of our training model is not that far on how our model performs on predicting unseen data from our test data set. This is a good evidence that our training data is not overfitting or capturing noise from our training data set and setting it as a pattern to learn."
  },
  {
    "objectID": "projects/telecom_churn/churn_telecom.html#decision-tree-model-with-k-cross-fold-validation",
    "href": "projects/telecom_churn/churn_telecom.html#decision-tree-model-with-k-cross-fold-validation",
    "title": "Telecom Customer Churn Analysis",
    "section": "Decision Tree Model with K-Cross Fold Validation",
    "text": "Decision Tree Model with K-Cross Fold Validation\nIt is good to know that using only our base model, we were able to get an accuracy of 86%, but we wont stop on that point. It is always recommended to check at least 3 modelling algorithm for comparison. For our 2nd model algorithm, we will use Decision Tree with k-Cross Fold Validation.\n\nData Split\n\nset.seed(1234)\ncolnames(churn_data_model) = str_replace_all(colnames(churn_data_model),\" \",\"_\") \n\ndtree_split = initial_split(churn_data_model)\ndtree_train = training(dtree_split)\ndtree_test = testing(dtree_split)\n\n#Setting up fold value\ndtree_fold = vfold_cv(dtree_train,v = 10)\n\n\n\nModel Recipe and Engine Initialization\n\ndtree_recipe = recipe(Churn ~ ., data= dtree_train) %&gt;% \n  step_normalize(all_numeric())\n\ntree_model = decision_tree() %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\nWorkflow and Model Fitting\n\ndtree_wf = workflow() %&gt;% \n  add_model(tree_model) %&gt;% \n  add_recipe(dtree_recipe)\n\nset.seed(1120)\ndtree_churn_cv_fit = dtree_wf %&gt;% \n  fit_resamples(dtree_fold)\n\ncollect_metrics(dtree_churn_cv_fit)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.922    10 0.00397 Preprocessor1_Model1\n2 roc_auc  binary     0.885    10 0.00903 Preprocessor1_Model1\n\n\nSo for our training model, our average Accuracy is at 92%. Impressive performance on our train data set. Let’s check if what will be the performance of our model on test data set.\n\n\nModel Evaluation\n\ndtree_fit = dtree_wf %&gt;% \n  fit(data = dtree_train)\n\ndtree_aug = augment(dtree_fit,dtree_test)\n\ndtree_aug %&gt;% \n  head()\n\n# A tibble: 6 × 21\n  .pred_class .pred_0 .pred_1 State International_plan Voice_mail_plan\n  &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;              &lt;chr&gt;          \n1 0             0.972  0.0276 LA    No                 No             \n2 0             0.972  0.0276 VA    No                 No             \n3 0             0.972  0.0276 VT    No                 Yes            \n4 0             0.972  0.0276 MA    No                 No             \n5 0             0.972  0.0276 OR    No                 No             \n6 0             0.972  0.0276 WY    No                 No             \n# ℹ 15 more variables: Number_vmail_messages &lt;int&gt;, Total_day_minutes &lt;dbl&gt;,\n#   Total_day_calls &lt;int&gt;, Total_day_charge &lt;dbl&gt;, Total_eve_minutes &lt;dbl&gt;,\n#   Total_eve_calls &lt;int&gt;, Total_eve_charge &lt;dbl&gt;, Total_night_minutes &lt;dbl&gt;,\n#   Total_night_calls &lt;int&gt;, Total_night_charge &lt;dbl&gt;,\n#   Total_intl_minutes &lt;dbl&gt;, Total_intl_calls &lt;int&gt;, Total_intl_charge &lt;dbl&gt;,\n#   Customer_service_calls &lt;int&gt;, Churn &lt;fct&gt;\n\n\nLet’s also take a look on the selected important features of our data.\n\ntree_plot = dtree_fit %&gt;% \n  pull_workflow_fit() \nrpart.plot(tree_plot$fit)\n\n\n\n\n\ndtree_aug %&gt;% \n  roc_curve(truth = Churn,.pred_0) %&gt;% \n  autoplot()\n\n\n\ndtree_aug %&gt;% \n  roc_curve(truth = Churn,.pred_1) %&gt;% \n  autoplot()\n\n\n\n\n\ndtree_testing_pred = predict(dtree_fit, dtree_test) %&gt;% \n  bind_cols(predict(dtree_fit, dtree_test, type = \"prob\")) %&gt;% \n  bind_cols(dtree_test %&gt;% select(Churn))\n\ndtree_testing_pred\n\n# A tibble: 834 × 4\n   .pred_class .pred_0 .pred_1 Churn\n   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;\n 1 0             0.972  0.0276 0    \n 2 0             0.972  0.0276 0    \n 3 0             0.972  0.0276 0    \n 4 0             0.972  0.0276 0    \n 5 0             0.972  0.0276 0    \n 6 0             0.972  0.0276 0    \n 7 0             0.843  0.157  0    \n 8 0             0.972  0.0276 0    \n 9 0             0.972  0.0276 0    \n10 0             0.972  0.0276 1    \n# ℹ 824 more rows\n\ndtree_testing_pred %&gt;% \n  accuracy(truth = Churn, .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.927\n\n\nAmazing! We now have a better performing model by using Decision Tree! Let’s try to add one last model. Who know, maybe we can even reach an accuracy rate of 95% right? On our next model we will use XGBoost."
  },
  {
    "objectID": "projects/telecom_churn/churn_telecom.html#xgboost-modelling-with-cross-fold-validation",
    "href": "projects/telecom_churn/churn_telecom.html#xgboost-modelling-with-cross-fold-validation",
    "title": "Telecom Customer Churn Analysis",
    "section": "XGBoost Modelling with Cross-Fold Validation",
    "text": "XGBoost Modelling with Cross-Fold Validation\n\nData Split\n\nxg_split = initial_split(\n  churn_data_model,\n  prop = 3/4,\n  strata = Churn\n)\n\nxg_train = training(xg_split)\nxg_test = testing(xg_split)\n\nxg_cv_fold = vfold_cv(xg_train, v = 10)\n\nxg_recipe = recipe( Churn ~ ., data = xg_train) %&gt;% \n  step_normalize(all_numeric()) %&gt;% \n  prep()\n\n\n\nXGBoost Model Specification\n\n#XGBoost Model Specs\nxgboost_model = boost_tree(\n  mode = \"classification\",\n  trees = 100,\n  min_n = tune(),\n  tree_depth = tune(),\n  learn_rate = tune(),\n  loss_reduction = tune()\n) %&gt;% \n  set_engine(\"xgboost\") %&gt;% \n  set_mode(\"classification\")\n\n#Grid Specification for Parameters\nxgboos_params = dials::parameters(\n  min_n(),\n    tree_depth(),\n    learn_rate(),\n    loss_reduction()\n)\n\n#Set up Grid Space\nxgboost_grid = dials::grid_max_entropy(\n  xgboos_params,\n  size = 60\n)\nknitr::kable(head(xgboost_grid))\n\n\n\n\nmin_n\ntree_depth\nlearn_rate\nloss_reduction\n\n\n\n\n5\n4\n0.0024475\n4.9402795\n\n\n16\n10\n0.0000000\n0.0000000\n\n\n7\n6\n0.0000010\n0.0000000\n\n\n22\n7\n0.0000000\n0.0000000\n\n\n6\n12\n0.0000001\n0.0000000\n\n\n11\n8\n0.0061443\n0.0000146\n\n\n\n\n\n\n\nDefine Worklow\n\nxgboost_wf = workflow() %&gt;% \n  add_model(xgboost_model) %&gt;% \n  add_formula(Churn ~ .)\n\n\n\nTune the Model\n\nxgboost_tuned = tune_grid(\n  object = xgboost_wf,\n  resamples = xg_cv_fold,\n  grid = xgboost_grid,\n  metrics = metric_set(accuracy, roc_auc),\n  control = control_grid(verbose = TRUE)\n)\n\nNow that we are done with Model Tuning, let’s explore the result of the object.\n\nxgboost_tuned %&gt;% \n  tune::show_best(metric = \"accuracy\")\n\n# A tibble: 5 × 10\n  min_n tree_depth   learn_rate loss_reduction .metric  .estimator  mean     n\n  &lt;int&gt;      &lt;int&gt;        &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;\n1     3         11 0.00110            8.83e- 1 accuracy binary     0.938    10\n2    19          5 0.0632             7.00e-10 accuracy binary     0.937    10\n3     4          8 0.000107           1.31e- 5 accuracy binary     0.934    10\n4     6         12 0.0000000980       5.69e- 9 accuracy binary     0.928    10\n5     7          6 0.000000984        9.60e-10 accuracy binary     0.926    10\n# ℹ 2 more variables: std_err &lt;dbl&gt;, .config &lt;chr&gt;\n\n\nNext, we will isolate the best performing hyperparameter values.\n\nxgboost_best_params = xgboost_tuned %&gt;% \n  select_best(\"accuracy\")\n\nxgboost_best_params\n\n# A tibble: 1 × 5\n  min_n tree_depth learn_rate loss_reduction .config              \n  &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;                \n1     3         11    0.00110          0.883 Preprocessor1_Model13\n\n\nFinalize the XGBoost model to use the best tuning parameters.\n\nxgboost_model_final = xgboost_model %&gt;% \n  finalize_model(xgboost_best_params)\n\nNow that we have our final model, let’s test it using our training model first. This is a recommended way of checking if our model is overfitting.\n\ntrain_processed = bake(xg_recipe, new_data = xg_train)\n\ntrain_prediction = xgboost_model_final %&gt;% \n  fit(\n    formula = Churn ~ .,\n    data = train_processed\n  ) %&gt;% \n  predict(new_data = train_processed) %&gt;% \n  bind_cols(xg_train)\n\nxgboost_score_train = train_prediction %&gt;% \n  metrics(Churn, .pred_class)\n\n\nxgboost_score_train\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.953\n2 kap      binary         0.798\n\n\nWe have 96% accuracy for training data. Let’s check the performance of our model on our testing data.\n\ntest_process = bake(xg_recipe, new_data = xg_test)\n\ntest_prediction = xgboost_model_final %&gt;% \n  fit(\n    formula = Churn ~ ., \n    data = test_process\n  ) %&gt;% \n  predict(new_data = test_process) %&gt;% \n  bind_cols(xg_test)\n\n\n\nxgboost_score_test = test_prediction %&gt;% \n  metrics(Churn, .pred_class)\n\n\nxgboost_score_test\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.923\n2 kap      binary         0.647\n\n\nXGBoost model resulted to an almost same performing model with the Decision Tree model. We can either select XGboost or Decision Tree for our Final model. For me, I will just settle with Decision Tree. We will still have the 92% accurate model with a simple model implementation and for that I think Decision Tree is a good choice."
  }
]